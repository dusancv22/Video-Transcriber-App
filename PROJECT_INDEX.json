{
  "indexed_at": "2025-10-22T16:59:49.952529",
  "root": ".",
  "project_structure": {
    "type": "tree",
    "root": ".",
    "tree": [
      ".",
      "+-- assets/",
      "|   `-- icons/",
      "+-- docs/",
      "|   +-- analysis/",
      "|   +-- api/",
      "|   +-- debug/",
      "|   +-- reports/",
      "|   +-- testing/",
      "|   `-- user_guide/",
      "+-- output/",
      "|   +-- logs/",
      "|   `-- transcripts/",
      "+-- resources/ (1 files)",
      "|   +-- config_templates/",
      "|   +-- icons/",
      "|   `-- styles/",
      "+-- src/ (47 files)",
      "|   +-- audio_processing/ (5 files)",
      "|   +-- config/ (2 files)",
      "|   +-- input_handling/ (4 files)",
      "|   +-- post_processing/ (5 files)",
      "|   +-- subtitles/ (6 files)",
      "|   +-- transcription/ (6 files)",
      "|   +-- translation/ (7 files)",
      "|   |   +-- engines/ (3 files)",
      "|   |   `-- utils/ (2 files)",
      "|   +-- ui/ (8 files)",
      "|   |   `-- styles/ (1 files)",
      "|   `-- utils/ (3 files)",
      "+-- temp/",
      "|   +-- audio/",
      "|   `-- segments/",
      "+-- tests/ (18 files)",
      "|   +-- test_audio_processing/ (4 files)",
      "|   |   `-- test_files/ (1 files)",
      "|   +-- test_input_handling/ (1 files)",
      "|   +-- test_post_processing/",
      "|   +-- test_repetition_fix/ (6 files)",
      "|   +-- test_transcription/ (6 files)",
      "|   |   `-- test_files/ (2 files)",
      "|   |       +-- output/ (1 files)",
      "|   |       `-- transcripts/",
      "|   `-- test_utils/",
      "+-- README.md",
      "+-- requirements.txt",
      "`-- setup.py"
    ]
  },
  "documentation_map": {
    "AGENTS.md": {
      "sections": [
        "Repository Guidelines",
        "Project Structure & Module Organization",
        "Build, Test, and Development Commands",
        "Coding Style & Naming Conventions",
        "Testing Guidelines",
        "Commit & Pull Request Guidelines"
      ],
      "architecture_hints": [
        "ui/"
      ]
    },
    "ARCHIVED_TASKS.md": {
      "sections": [
        "ARCHIVED_TASKS.md",
        "Archive Date: 2025-08-06",
        "Transcription Bug Fix: Word Repetition Issue",
        "Implementation Phase",
        "Testing and Validation",
        "Bug Fix Statistics"
      ],
      "architecture_hints": []
    },
    "BUILD_EXECUTABLE.md": {
      "sections": [
        "Building Video Transcriber Executable",
        "Prerequisites",
        "Build Methods",
        "Method 1: Quick Build (Smaller, Requires Dependencies)",
        "Method 2: Full Build with All Dependencies (Recommended)",
        "Method 3: Custom Build with Hidden Imports",
        "Important Notes for Translation Support",
        "Including Translation Models",
        "FFmpeg Requirements",
        "Build Output"
      ],
      "architecture_hints": []
    },
    "CLAUDE.md": {
      "sections": [
        "CLAUDE.md",
        "Project Overview",
        "Key Goals",
        "Target Users",
        "Development Commands",
        "Standard build",
        "Full build with all dependencies (uses existing spec file)",
        "Subtitle Synchronization System",
        "Architecture Overview",
        "System Architecture Layers"
      ],
      "architecture_hints": []
    },
    "PLANNING.md": {
      "sections": [
        "PLANNING.md",
        "Project Overview",
        "Key Goals",
        "Technology Stack",
        "Core Technologies",
        "Development Tools",
        "Dependencies",
        "User Personas",
        "Primary User: Content Creator/Researcher",
        "Secondary User: Accessibility Professional"
      ],
      "architecture_hints": []
    },
    "README.md": {
      "sections": [
        "Video Transcriber App",
        "??? Features",
        "???? Installation",
        "Option 1: Download Pre-built Executable (Windows)",
        "Option 2: Run from Source",
        "Windows",
        "macOS/Linux",
        "For CUDA 11.8",
        "For CUDA 12.1",
        "For CPU only"
      ],
      "architecture_hints": []
    },
    "TASKS.md": {
      "sections": [
        "TASKS.md",
        "Current Development Status",
        "Active Tasks",
        "Final Validation & Deployment",
        "Repository Cleanup - IMMEDIATE",
        "Technical Debt - LOW PRIORITY",
        "Documentation - LOW PRIORITY",
        "Statistics",
        "Current Focus Areas",
        "\ud83d\ude80 IMMEDIATE PRIORITIES:"
      ],
      "architecture_hints": []
    },
    "docs\\subtitle-sync-complete-context.md": {
      "sections": [
        "Subtitle Synchronization Issue - Complete Context & Status",
        "The Core Problem",
        "Specific Example",
        "Root Cause Discovery",
        "The Critical Finding",
        "Why Word Timestamps Are Missing",
        "What We Attempted",
        "1. Word-Level Timestamp Analysis System",
        "2. Pipeline Modifications",
        "3. Configuration Attempts"
      ],
      "architecture_hints": []
    },
    "docs\\subtitle-sync-solution.md": {
      "sections": [
        "Subtitle Synchronization Solution - Implementation Complete",
        "Problem Solved",
        "Solution Implemented",
        "1. Word-Level Timestamp Analysis (`src/subtitles/word_level_analyzer.py`)",
        "2. Configurable Transition Delay",
        "3. Natural Segment Boundary Detection",
        "Key Features",
        "Word-Level Optimization",
        "Enabled by default in the pipeline",
        "Configurable Settings"
      ],
      "architecture_hints": []
    },
    "docs\\subtitle-synchronization-architecture.md": {
      "sections": [
        "Subtitle Synchronization & Translation Architecture",
        "Overview",
        "The Problem",
        "The Solution",
        "Architecture Components",
        "1. Enhanced Whisper Manager (`src/transcription/enhanced_whisper_manager.py`)",
        "2. Word-Based Subtitle Generator (`src/subtitles/word_based_subtitle_generator.py`)",
        "3. Transcription Pipeline Integration (`src/transcription/transcription_pipeline.py`)",
        "CRITICAL BUG FIX: Preserve word timestamps when adjusting segments",
        "4. UI Integration (`src/ui/main_window.py`)"
      ],
      "architecture_hints": []
    },
    "docs\\subtitle-synchronization-fix.md": {
      "sections": [
        "Subtitle Synchronization Fix - Complete Analysis & Solution",
        "Executive Summary",
        "Problem Description",
        "Original Issue (FIXED)",
        "Current Issue (NEEDS FIX)",
        "What We've Implemented",
        "1. VAD System Integration",
        "2. Enhanced Whisper Manager",
        "3. Updated Pipeline Integration",
        "4. Dependencies Added"
      ],
      "architecture_hints": []
    },
    "docs\\subtitle-timing-analysis.md": {
      "sections": [
        "Subtitle Timing Synchronization Analysis & Future Improvements",
        "Executive Summary",
        "Current Implementation Status",
        "\u2705 Successfully Implemented Features",
        "\u274c Unresolved Issues",
        "Root Cause Analysis",
        "The Fundamental Problem",
        "Why This Happens",
        "Proposed Solution Architecture",
        "Approach 1: Voice Activity Detection (VAD) Integration"
      ],
      "architecture_hints": []
    },
    "docs\\UI_MODERNIZATION.md": {
      "sections": [
        "Video Transcriber App - UI Modernization Documentation",
        "Overview",
        "Key Improvements",
        "1. Design System Implementation",
        "2. Color Palette",
        "3. Component Enhancements",
        "4. Typography System",
        "5. Spacing System",
        "6. Visual Effects",
        "File Structure"
      ],
      "architecture_hints": []
    },
    "tests\\REPETITION_FIX_TEST_REPORT.md": {
      "sections": [
        "Repetition Bug Fix Validation Report",
        "Executive Summary",
        "Current Test Status",
        "\u2705 Existing Tests Status",
        "\u2705 Fixed Issues",
        "Repetition Bug Fix Implementation Status",
        "\u274c Missing Implementation: Audio Segmentation with Overlap",
        "Current AudioSplitter.split_audio() creates clean segments without overlap",
        "\u274c Missing Implementation: Enhanced Whisper Configuration",
        "\u274c Missing Implementation: Smart Text Deduplication"
      ],
      "architecture_hints": []
    },
    "assets\\icons\\icon_design_spec.md": {
      "sections": [
        "Video Transcriber App Icon Design Specification",
        "Icon Concept: Video-to-Text Transformation",
        "Visual Design",
        "Design Elements",
        "Color Palette",
        "Size Requirements",
        "File Formats",
        "Design Style",
        "Implementation Notes",
        "Placeholder Implementation"
      ],
      "architecture_hints": []
    }
  },
  "directory_purposes": {
    "docs": "Project documentation",
    "src": "Source code root directory",
    "tests": "Test files and test utilities",
    "assets\\icons": "Test files and test utilities",
    "src\\config": "Configuration files and settings",
    "src\\utils": "Shared utility functions and helpers",
    "tests\\test_audio_processing": "Test files and test utilities",
    "tests\\test_input_handling": "Test files and test utilities",
    "tests\\test_repetition_fix": "Test files and test utilities",
    "tests\\test_transcription": "Test files and test utilities",
    "tests\\test_audio_processing\\test_files": "Test files and test utilities",
    "tests\\test_transcription\\test_files": "Test files and test utilities",
    "src\\translation\\utils": "Shared utility functions and helpers"
  },
  "stats": {
    "total_files": 75,
    "total_directories": 50,
    "fully_parsed": {
      "python": 73
    },
    "listed_only": {
      "json": 2
    },
    "markdown_files": 15
  },
  "files": {
    "PROJECT_INDEX.json": {
      "language": "json",
      "parsed": false
    },
    "run.py": {
      "language": "python",
      "parsed": true,
      "imports": [
        "sys",
        "pathlib",
        "src.ui.main_window",
        "PyQt6.QtWidgets"
      ],
      "functions": {
        "main": "()"
      },
      "classes": {},
      "call_graph": {}
    },
    "setup.py": {
      "language": "python",
      "parsed": false
    },
    "test_direct_translation.py": {
      "language": "python",
      "parsed": true,
      "purpose": "Test file",
      "imports": [
        "sys",
        "pathlib",
        "traceback",
        "src.translation.subtitle_translator"
      ],
      "functions": {
        "test_direct_translation": {
          "doc": "Test translating a subtitle file directly.",
          "signature": "()",
          "called_by": [
            "main"
          ]
        }
      },
      "classes": {},
      "call_graph": {}
    },
    "test_portuguese_translation.py": {
      "language": "python",
      "parsed": true,
      "purpose": "Test file",
      "imports": [
        "sys",
        "os",
        "pathlib",
        "src.translation.subtitle_translator",
        "src.translation.engines.tower_translator",
        "torch",
        "src.translation.utils.language_detector",
        "traceback"
      ],
      "functions": {
        "test_gpu_availability": {
          "doc": "Test if GPU meets requirements for TowerInstruct.",
          "signature": "()",
          "called_by": [
            "main"
          ]
        },
        "test_direct_translation": {
          "doc": "Test direct Portuguese to English translation.",
          "signature": "()",
          "called_by": [
            "main"
          ]
        },
        "test_subtitle_file_translation": {
          "doc": "Test translating a subtitle file from Portuguese to English.",
          "signature": "()",
          "called_by": [
            "main"
          ]
        },
        "test_language_detection": {
          "doc": "Test Portuguese language detection.",
          "signature": "()",
          "called_by": [
            "main"
          ]
        },
        "main": {
          "doc": "Run all tests.",
          "calls": [
            "test_direct_translation",
            "test_gpu_availability",
            "test_language_detection",
            "test_subtitle_file_translation"
          ],
          "signature": "()"
        }
      },
      "classes": {},
      "call_graph": {}
    },
    "test_translation.py": {
      "language": "python",
      "parsed": true,
      "purpose": "Test file",
      "imports": [
        "sys",
        "pathlib",
        "src.translation.subtitle_translator",
        "src.translation.engines.helsinki_translator"
      ],
      "functions": {
        "test_basic_translation": {
          "doc": "Test basic Spanish to English translation.",
          "signature": "()",
          "called_by": [
            "main"
          ]
        },
        "test_subtitle_segments": {
          "doc": "Test translation of subtitle-like segments.",
          "signature": "()",
          "called_by": [
            "main"
          ]
        },
        "test_context_translation": {
          "doc": "Test context-aware translation.",
          "signature": "()",
          "called_by": [
            "main"
          ]
        },
        "main": {
          "doc": "Run all tests.",
          "calls": [
            "test_basic_translation",
            "test_context_translation",
            "test_subtitle_segments"
          ],
          "signature": "()"
        }
      },
      "classes": {},
      "call_graph": {}
    },
    "test_ui_crash.py": {
      "language": "python",
      "parsed": true,
      "purpose": "Test file",
      "imports": [
        "sys",
        "pathlib",
        "PyQt6.QtWidgets",
        "src.ui.styles.modern_theme",
        "traceback",
        "src.translation.engines.tower_translator",
        "traceback"
      ],
      "functions": {
        "test_color_access": {
          "doc": "Test if we can access ModernTheme colors.",
          "signature": "()"
        },
        "test_translation_check": {
          "doc": "Test the translation check logic.",
          "signature": "()"
        }
      },
      "classes": {},
      "call_graph": {}
    },
    "__init__.py": {
      "language": "python",
      "parsed": false
    },
    ".claude\\settings.local.json": {
      "language": "json",
      "parsed": false,
      "purpose": "Configuration"
    },
    "resources\\__init__.py": {
      "language": "python",
      "parsed": false
    },
    "src\\__init__.py": {
      "language": "python",
      "parsed": false
    },
    "tests\\__init__.py": {
      "language": "python",
      "parsed": false
    },
    "tests\\test_audio_processing\\test_converter.py": {
      "language": "python",
      "parsed": true,
      "purpose": "Test file",
      "imports": [
        "pytest",
        "src.audio_processing.converter",
        "pathlib",
        "os"
      ],
      "functions": {},
      "classes": {
        "TestAudioConverter": {
          "methods": {
            "setup_method": "(self)",
            "test_convert_video_to_audio": "(self, tmp_path)",
            "test_invalid_video_path": "(self)",
            "teardown_method": "(self)"
          }
        }
      },
      "call_graph": {}
    },
    "tests\\test_audio_processing\\test_splitter.py": {
      "language": "python",
      "parsed": true,
      "purpose": "Test file",
      "imports": [
        "unittest",
        "pathlib",
        "shutil",
        "sys",
        "src.audio_processing.splitter"
      ],
      "functions": {},
      "classes": {
        "TestAudioSplitter": {
          "methods": {
            "setUp": {
              "doc": "Set up test environment.",
              "signature": "(self)"
            },
            "test_audio_splitting": {
              "doc": "Test splitting of audio file.",
              "signature": "(self)"
            }
          },
          "inherits": [
            "unittest.TestCase"
          ]
        }
      },
      "call_graph": {}
    },
    "tests\\test_audio_processing\\__init__.py": {
      "language": "python",
      "parsed": false
    },
    "tests\\test_input_handling\\test_file_handler.py": {
      "language": "python",
      "parsed": true,
      "purpose": "Test file",
      "imports": [
        "pytest",
        "src.input_handling.file_handler",
        "os"
      ],
      "functions": {},
      "classes": {
        "TestFileHandler": {
          "methods": {
            "setup_method": "(self)",
            "test_validate_file_invalid_extension": {
              "doc": "Test validation of file with invalid extension",
              "signature": "(self)"
            },
            "test_validate_file_nonexistent": {
              "doc": "Test validation of non-existent file",
              "signature": "(self)"
            },
            "test_queue_management": {
              "doc": "Test queue management functions",
              "signature": "(self)"
            }
          }
        }
      },
      "call_graph": {}
    },
    "tests\\test_repetition_fix\\test_audio_segmentation.py": {
      "language": "python",
      "parsed": true,
      "purpose": "Test file",
      "imports": [
        "pytest",
        "pathlib",
        "tempfile",
        "shutil",
        "unittest.mock",
        "pydub",
        "numpy",
        "src.audio_processing.splitter"
      ],
      "functions": {},
      "classes": {
        "TestAudioSegmentationWithOverlap": {
          "methods": {
            "setup_method": {
              "doc": "Set up test environment.",
              "signature": "(self)"
            },
            "teardown_method": {
              "doc": "Clean up test environment.",
              "signature": "(self)"
            },
            "create_test_audio": {
              "doc": "Create a test audio file.",
              "signature": "(self, duration_ms=60000, sample_rate=44100)",
              "called_by": [
                "TestAudioSegmentationWithOverlap.test_no_overlap_for_small_files",
                "TestAudioSegmentationWithOverlap.test_overlap_is_applied_when_splitting"
              ]
            },
            "test_overlap_is_applied_when_splitting": {
              "doc": "Test that overlap is properly applied when splitting large audio files.",
              "calls": [
                "create_test_audio"
              ],
              "signature": "(self)"
            },
            "test_overlap_duration_is_correct": {
              "doc": "Test that the overlap duration is 2.5 seconds as specified.",
              "signature": "(self)"
            },
            "test_no_overlap_for_small_files": {
              "doc": "Test that small files (under threshold) don't get unnecessary overlap.",
              "calls": [
                "create_test_audio"
              ],
              "signature": "(self)"
            },
            "test_overlap_prevents_word_cut_off": {
              "doc": "Test that overlap prevents words from being cut off between segments.",
              "signature": "(self)"
            },
            "test_segment_boundaries_with_overlap": {
              "doc": "Test that segment boundaries are calculated correctly with overlap.",
              "signature": "(self)"
            }
          },
          "doc": "Test audio segmentation with overlap functionality."
        },
        "TestOverlapConfiguration": {
          "methods": {
            "test_default_overlap_duration": {
              "doc": "Test that default overlap duration is 2.5 seconds.",
              "signature": "(self)"
            },
            "test_configurable_overlap_duration": {
              "doc": "Test that overlap duration can be configured.",
              "signature": "(self)"
            },
            "test_overlap_minimum_segment_size": {
              "doc": "Test that overlap doesn't create segments smaller than minimum size.",
              "signature": "(self)"
            }
          },
          "doc": "Test overlap configuration and parameters."
        }
      },
      "call_graph": {}
    },
    "tests\\test_repetition_fix\\test_integration.py": {
      "language": "python",
      "parsed": true,
      "purpose": "Test file",
      "imports": [
        "pytest",
        "unittest.mock",
        "pathlib",
        "tempfile",
        "shutil",
        "src.transcription.transcription_pipeline",
        "src.post_processing.text_processor",
        "src.post_processing.text_processor",
        "src.post_processing.text_processor",
        "src.post_processing.text_processor"
      ],
      "functions": {},
      "classes": {
        "TestRepetitionFixIntegration": {
          "methods": {
            "setup_method": {
              "doc": "Set up test environment.",
              "signature": "(self)"
            },
            "teardown_method": {
              "doc": "Clean up test environment.",
              "signature": "(self)"
            },
            "test_end_to_end_repetition_prevention": {
              "decorators": [
                "patch",
                "patch"
              ],
              "doc": "Test the complete pipeline prevents repetition from input to output.",
              "signature": "(self, mock_converter, mock_whisper_manager)"
            },
            "test_repetition_detection_in_real_scenario": {
              "doc": "Test detection of repetition patterns in realistic scenarios.",
              "signature": "(self)"
            },
            "test_overlap_boundary_handling": {
              "doc": "Test that overlap boundaries don't create artificial repetition.",
              "signature": "(self)"
            },
            "test_whisper_parameters_prevent_repetition": {
              "doc": "Test that Whisper parameters effectively prevent repetitive output.",
              "signature": "(self)"
            },
            "test_large_file_segmentation_flow": {
              "decorators": [
                "patch",
                "patch"
              ],
              "doc": "Test the complete flow for large files requiring segmentation.",
              "calls": [
                "mock_transcribe"
              ],
              "signature": "(self, mock_converter, mock_whisper_manager)"
            },
            "mock_transcribe": {
              "signature": "(audio_file)",
              "called_by": [
                "TestRepetitionFixIntegration.test_large_file_segmentation_flow"
              ]
            },
            "test_regression_no_repetition_for_small_files": {
              "doc": "Test that small files (no segmentation) don't introduce repetition.",
              "signature": "(self)"
            }
          },
          "doc": "Integration tests for the complete repetition fix pipeline."
        },
        "TestRepetitionFixRegressionTests": {
          "methods": {
            "test_normal_transcription_quality_maintained": {
              "doc": "Test that transcription quality is maintained after repetition fixes.",
              "signature": "(self)"
            },
            "test_punctuation_preservation": {
              "doc": "Test that punctuation is preserved correctly after repetition fixes.",
              "signature": "(self)"
            },
            "test_technical_terms_preservation": {
              "doc": "Test that technical terms and proper nouns are preserved.",
              "signature": "(self)"
            }
          },
          "doc": "Regression tests to ensure repetition fix doesn't break existing functionality."
        }
      },
      "call_graph": {}
    },
    "tests\\test_repetition_fix\\test_text_combiner.py": {
      "language": "python",
      "parsed": true,
      "purpose": "Test file",
      "imports": [
        "pytest",
        "unittest.mock",
        "pathlib",
        "tempfile",
        "src.post_processing.combiner",
        "src.post_processing.combiner"
      ],
      "functions": {},
      "classes": {
        "TestTextCombiner": {
          "methods": {
            "setup_method": {
              "doc": "Set up test environment.",
              "signature": "(self)"
            },
            "test_combines_segments_without_repetition": {
              "doc": "Test that segments are combined without creating repetition.",
              "signature": "(self)"
            },
            "test_identifies_overlap_regions": {
              "doc": "Test that overlapping regions between segments are identified correctly.",
              "signature": "(self)"
            },
            "test_handles_partial_word_overlap": {
              "doc": "Test handling of partial word overlaps at segment boundaries.",
              "signature": "(self)"
            },
            "test_preserves_punctuation_during_merge": {
              "doc": "Test that punctuation is preserved correctly during segment merging.",
              "signature": "(self)"
            },
            "test_handles_no_overlap_segments": {
              "doc": "Test handling of segments with no overlap.",
              "signature": "(self)"
            },
            "test_similarity_threshold_configuration": {
              "doc": "Test that similarity threshold for overlap detection can be configured.",
              "signature": "(self)"
            },
            "test_minimum_overlap_length": {
              "doc": "Test that minimum overlap length can be configured.",
              "signature": "(self)"
            }
          },
          "doc": "Test TextCombiner functionality for intelligent segment merging."
        },
        "TestTextCombinerAlgorithms": {
          "methods": {
            "test_longest_common_substring_detection": {
              "doc": "Test longest common substring detection for overlap identification.",
              "signature": "(self)"
            },
            "test_fuzzy_matching_for_similar_phrases": {
              "doc": "Test fuzzy matching to detect similar but not identical phrases.",
              "signature": "(self)"
            },
            "test_word_level_overlap_detection": {
              "doc": "Test word-level overlap detection (not just character-level).",
              "signature": "(self)"
            },
            "test_semantic_similarity_detection": {
              "doc": "Test detection of semantically similar overlaps.",
              "signature": "(self)"
            }
          },
          "doc": "Test different algorithms for text combination."
        },
        "TestTextCombinerErrorHandling": {
          "methods": {
            "setup_method": {
              "doc": "Set up test environment.",
              "signature": "(self)"
            },
            "test_empty_segments_list": {
              "doc": "Test handling of empty segments list.",
              "signature": "(self)"
            },
            "test_single_segment": {
              "doc": "Test handling of single segment.",
              "signature": "(self)"
            },
            "test_none_values_in_segments": {
              "doc": "Test handling of None values in segments list.",
              "signature": "(self)"
            },
            "test_whitespace_only_segments": {
              "doc": "Test handling of whitespace-only segments.",
              "signature": "(self)"
            }
          },
          "doc": "Test error handling in TextCombiner."
        },
        "TestTextCombinerIntegration": {
          "methods": {
            "test_integration_with_audio_splitter_overlaps": {
              "doc": "Test integration with audio splitter overlap regions.",
              "signature": "(self)"
            },
            "test_integration_with_whisper_output": {
              "doc": "Test integration with actual Whisper transcription output.",
              "signature": "(self)"
            },
            "test_performance_with_large_segment_count": {
              "doc": "Test performance with many segments (from long audio files).",
              "signature": "(self)"
            }
          },
          "doc": "Integration tests for TextCombiner with other components."
        }
      },
      "call_graph": {}
    },
    "tests\\test_repetition_fix\\test_text_deduplication.py": {
      "language": "python",
      "parsed": true,
      "purpose": "Test file",
      "imports": [
        "pytest",
        "unittest.mock",
        "pathlib",
        "src.post_processing.text_processor",
        "time"
      ],
      "functions": {},
      "classes": {
        "TestTextDeduplication": {
          "methods": {
            "setup_method": {
              "doc": "Set up test environment.",
              "signature": "(self)"
            },
            "test_detects_repetitive_phrases": {
              "doc": "Test that repetitive phrases are detected correctly.",
              "signature": "(self)"
            },
            "test_preserves_legitimate_repetition": {
              "doc": "Test that legitimate repetition is preserved.",
              "signature": "(self)"
            },
            "test_removes_excessive_consecutive_repetition": {
              "doc": "Test that excessive consecutive repetition is removed.",
              "signature": "(self)"
            },
            "test_handles_punctuation_in_repetitive_text": {
              "doc": "Test that punctuation variations in repetitive text are handled.",
              "signature": "(self)"
            },
            "test_deduplication_threshold_configuration": {
              "doc": "Test that deduplication threshold can be configured.",
              "signature": "(self)"
            },
            "test_deduplication_window_size": {
              "doc": "Test deduplication within a sliding window of text.",
              "signature": "(self)"
            },
            "test_semantic_deduplication": {
              "doc": "Test that semantically similar repetitive phrases are detected.",
              "signature": "(self)"
            }
          },
          "doc": "Test text deduplication functionality."
        },
        "TestDeduplicationEdgeCases": {
          "methods": {
            "setup_method": {
              "doc": "Set up test environment.",
              "signature": "(self)"
            },
            "test_empty_text_deduplication": {
              "doc": "Test deduplication with empty or whitespace-only text.",
              "signature": "(self)"
            },
            "test_single_word_repetition": {
              "doc": "Test handling of single word repeated many times.",
              "signature": "(self)"
            },
            "test_mixed_case_repetition": {
              "doc": "Test repetition detection across different cases.",
              "signature": "(self)"
            },
            "test_deduplication_preserves_sentence_structure": {
              "doc": "Test that deduplication preserves overall sentence structure.",
              "signature": "(self)"
            },
            "test_deduplication_with_numbers_and_special_chars": {
              "doc": "Test deduplication with numbers and special characters.",
              "signature": "(self)"
            }
          },
          "doc": "Test edge cases for text deduplication."
        },
        "TestDeduplicationPerformance": {
          "methods": {
            "setup_method": {
              "doc": "Set up test environment.",
              "signature": "(self)"
            },
            "test_deduplication_large_text_performance": {
              "doc": "Test that deduplication performs well on large texts.",
              "signature": "(self)"
            },
            "test_deduplication_memory_usage": {
              "doc": "Test that deduplication doesn't consume excessive memory.",
              "signature": "(self)"
            }
          },
          "doc": "Test performance aspects of deduplication."
        }
      },
      "call_graph": {}
    },
    "tests\\test_repetition_fix\\test_whisper_configuration.py": {
      "language": "python",
      "parsed": true,
      "purpose": "Test file",
      "imports": [
        "pytest",
        "unittest.mock",
        "pathlib",
        "tempfile",
        "src.transcription.whisper_manager",
        "shutil"
      ],
      "functions": {},
      "classes": {
        "TestWhisperRepetitionPrevention": {
          "methods": {
            "setup_method": {
              "doc": "Set up test environment.",
              "signature": "(self)"
            },
            "teardown_method": {
              "doc": "Clean up test environment.",
              "signature": "(self)"
            },
            "test_whisper_uses_repetition_prevention_parameters": {
              "decorators": [
                "patch"
              ],
              "doc": "Test that Whisper is configured with parameters to prevent repetition.",
              "signature": "(self, mock_load_model)"
            },
            "test_temperature_setting_for_consistency": {
              "decorators": [
                "patch"
              ],
              "doc": "Test that temperature is set to reduce randomness and potential repetition.",
              "signature": "(self, mock_load_model)"
            },
            "test_beam_search_configuration": {
              "decorators": [
                "patch"
              ],
              "doc": "Test that beam search is configured to prevent repetitive outputs.",
              "signature": "(self, mock_load_model)"
            },
            "test_repetition_penalty_parameter": {
              "decorators": [
                "patch"
              ],
              "doc": "Test that repetition penalty is applied to discourage repeated phrases.",
              "signature": "(self, mock_load_model)"
            },
            "test_fp16_disabled_for_accuracy": {
              "doc": "Test that FP16 is disabled for better accuracy and consistency.",
              "signature": "(self)"
            },
            "test_language_forced_to_english": {
              "decorators": [
                "patch"
              ],
              "doc": "Test that language is forced to English to prevent language detection issues.",
              "signature": "(self, mock_load_model)"
            },
            "test_repetition_detection_and_cleanup": {
              "doc": "Test that repetition detection and cleanup functions work correctly.",
              "signature": "(self)"
            },
            "test_transcription_uses_cleaned_text": {
              "decorators": [
                "patch"
              ],
              "doc": "Test that transcription returns cleaned text instead of raw text.",
              "signature": "(self, mock_load_model)"
            }
          },
          "doc": "Test Whisper configuration changes to prevent repetition."
        },
        "TestWhisperModelStability": {
          "methods": {
            "test_consistent_output_for_same_input": {
              "decorators": [
                "patch"
              ],
              "doc": "Test that Whisper produces consistent output for the same input.",
              "signature": "(self, mock_load_model)"
            },
            "test_model_initialization_stability": {
              "doc": "Test that model initialization is stable and repeatable.",
              "signature": "(self)"
            }
          },
          "doc": "Test Whisper model stability and consistency."
        }
      },
      "call_graph": {}
    },
    "tests\\test_repetition_fix\\__init__.py": {
      "language": "python",
      "parsed": false
    },
    "tests\\test_transcription\\test_pipeline.py": {
      "language": "python",
      "parsed": true,
      "purpose": "Test file",
      "imports": [
        "sys",
        "pathlib",
        "src.transcription.transcription_pipeline",
        "time"
      ],
      "functions": {
        "progress_callback": {
          "doc": "Simple progress callback to show pipeline progress",
          "signature": "(progress: float, status: str)",
          "called_by": [
            "TranscriptionWorker.run"
          ]
        },
        "test_pipeline": {
          "doc": "Test the complete transcription pipeline",
          "signature": "()"
        }
      },
      "classes": {},
      "call_graph": {}
    },
    "tests\\test_transcription\\test_queue.py": {
      "language": "python",
      "parsed": true,
      "purpose": "Test file",
      "imports": [
        "sys",
        "pathlib",
        "src.transcription.transcription_pipeline",
        "time"
      ],
      "functions": {
        "progress_callback": {
          "doc": "Simple progress callback to show pipeline progress",
          "signature": "(progress: float, status: str)",
          "called_by": [
            "TranscriptionWorker.run"
          ]
        },
        "test_multiple_files": {
          "doc": "Test processing multiple video files in sequence",
          "signature": "()"
        }
      },
      "classes": {},
      "call_graph": {}
    },
    "tests\\test_transcription\\test_whisper_manager.py": {
      "language": "python",
      "parsed": true,
      "purpose": "Test file",
      "imports": [
        "sys",
        "pathlib",
        "src.transcription.whisper_manager",
        "time"
      ],
      "functions": {
        "test_basic_transcription": {
          "doc": "Test basic MP3 transcription functionality",
          "signature": "()"
        }
      },
      "classes": {},
      "call_graph": {}
    },
    "tests\\test_transcription\\__init__.py": {
      "language": "python",
      "parsed": false
    },
    "tests\\test_transcription\\test_files\\__init__.py": {
      "language": "python",
      "parsed": false
    },
    "tests\\test_transcription\\test_files\\output\\__init__.py": {
      "language": "python",
      "parsed": false
    },
    "tests\\test_audio_processing\\test_files\\__init__.py": {
      "language": "python",
      "parsed": false
    },
    "src\\audio_processing\\converter.py": {
      "language": "python",
      "parsed": true,
      "imports": [
        "pathlib",
        "ffmpeg",
        "typing",
        "logging",
        "time",
        "os",
        "subprocess",
        "datetime"
      ],
      "functions": {},
      "classes": {
        "AudioConverter": {
          "methods": {
            "__init__": {
              "doc": "Initialize AudioConverter with output directory setup.",
              "signature": "(self)",
              "called_by": [
                "TranscriptionWorker.__init__",
                "MainWindow.__init__"
              ]
            },
            "get_last_split_metadata": "(self) -> list",
            "_get_audio_duration": {
              "signature": "(self, audio_path: str) -> float",
              "called_by": [
                "AudioConverter.split_audio_if_needed"
              ]
            },
            "_extract_audio_segment": {
              "signature": "(self, input_path: str, output_path: str, start_time: float, end_time: float) -> bool",
              "called_by": [
                "AudioConverter.split_audio_if_needed"
              ]
            },
            "check_file_size": {
              "signature": "(self, file_path: str) -> float",
              "called_by": [
                "AudioConverter.split_audio_if_needed"
              ]
            },
            "split_audio_if_needed": {
              "calls": [
                "_extract_audio_segment",
                "_get_audio_duration",
                "check_file_size"
              ],
              "signature": "(self, audio_path: str, max_size_mb: float = 25, overlap_seconds: float = 2.5)",
              "called_by": [
                "AudioConverter.convert_video_to_audio"
              ]
            },
            "convert_video_to_audio": {
              "calls": [
                "split_audio_if_needed"
              ],
              "signature": "(self, video_path: str, progress_callback: Optional[Callable[[float], None]] = None) -> Tuple[bool, list[str]]"
            },
            "cleanup_temp_files": {
              "doc": "Clean up temporary audio files with status reporting.",
              "signature": "(self)"
            }
          },
          "properties": [
            "list",
            "audio_path",
            "float",
            "input_path",
            "output_path",
            "start_time",
            "end_time",
            "bool",
            "file_path",
            "float",
            "audio_path",
            "max_size_mb",
            "overlap_seconds",
            "video_path",
            "progress_callback"
          ]
        }
      },
      "call_graph": {}
    },
    "src\\audio_processing\\optimizer.py": {
      "language": "python",
      "parsed": false
    },
    "src\\audio_processing\\splitter.py": {
      "language": "python",
      "parsed": true,
      "imports": [
        "pathlib",
        "typing",
        "math",
        "pydub",
        "logging"
      ],
      "functions": {},
      "classes": {
        "AudioSplitter": {
          "methods": {
            "__init__": {
              "doc": "Initialize AudioSplitter with maximum segment size.",
              "signature": "(self, max_size_mb: int = 25)",
              "called_by": [
                "TranscriptionWorker.__init__",
                "MainWindow.__init__"
              ]
            },
            "split_audio": {
              "calls": [
                "cleanup_segments"
              ],
              "signature": "(self, audio_path: str | Path) -> List[Path]"
            },
            "cleanup_segments": {
              "doc": "Clean up segment files and directory.",
              "signature": "(self, segments_dir: Path) -> None",
              "called_by": [
                "AudioSplitter.split_audio"
              ]
            },
            "get_segment_info": {
              "doc": "Get information about the segments.",
              "signature": "(self, segments: List[Path]) -> dict"
            }
          },
          "properties": [
            "audio_path"
          ]
        }
      },
      "call_graph": {}
    },
    "src\\audio_processing\\vad_manager.py": {
      "language": "python",
      "parsed": true,
      "imports": [
        "torch",
        "torchaudio",
        "pathlib",
        "typing",
        "logging",
        "numpy",
        "pydub",
        "pydub.utils",
        "tempfile",
        "os",
        "warnings"
      ],
      "functions": {},
      "classes": {
        "VADManager": {
          "methods": {
            "__init__": {
              "signature": "(self, threshold: float = 0.3, # Lower threshold for more sensitive detection min_speech_duration_ms: int = 100, # Shorter minimum to catch brief words min_silence_duration_ms: int = 300, # Longer silence to avoid over-splitting sample_rate: int = 16000)",
              "called_by": [
                "TranscriptionWorker.__init__",
                "MainWindow.__init__"
              ]
            },
            "_load_model": {
              "doc": "Load Silero VAD model.",
              "signature": "(self)",
              "called_by": [
                "VADManager.detect_speech_regions"
              ]
            },
            "detect_speech_regions": {
              "calls": [
                "_ensure_wav_format",
                "_load_model"
              ],
              "signature": "(self, audio_path: str | Path, return_milliseconds: bool = False) -> List[Dict[str, float]]",
              "called_by": [
                "VADManager.get_first_speech_time"
              ]
            },
            "_ensure_wav_format": {
              "signature": "(self, audio_path: Path) -> Path",
              "called_by": [
                "VADManager.detect_speech_regions"
              ]
            },
            "extract_audio_segment": "(self, audio_path: str | Path, start_time: float, end_time: float, output_path: Optional[str | Path] = None) -> Path",
            "merge_close_regions": "(self, regions: List[Dict[str, float]], max_gap: float = 0.5) -> List[Dict[str, float]]",
            "get_first_speech_time": {
              "calls": [
                "detect_speech_regions"
              ],
              "signature": "(self, audio_path: str | Path) -> float"
            },
            "calculate_speech_ratio": "(self, regions: List[Dict[str, float]], total_duration: float) -> float"
          },
          "doc": "Manages Voice Activity Detection using Silero VAD model.",
          "properties": [
            "threshold",
            "min_speech_duration_ms",
            "min_silence_duration_ms",
            "sample_rate",
            "audio_path",
            "return_milliseconds",
            "audio_path",
            "audio_path",
            "start_time",
            "end_time",
            "output_path",
            "regions",
            "max_gap",
            "audio_path",
            "regions",
            "total_duration"
          ]
        }
      },
      "call_graph": {}
    },
    "src\\audio_processing\\__init__.py": {
      "language": "python",
      "parsed": false
    },
    "src\\config\\settings.py": {
      "language": "python",
      "parsed": true,
      "purpose": "Configuration",
      "imports": [
        "json",
        "os",
        "pathlib",
        "typing",
        "logging"
      ],
      "functions": {},
      "classes": {
        "Settings": {
          "methods": {
            "__init__": {
              "doc": "Initialize settings manager",
              "calls": [
                "load_settings"
              ],
              "signature": "(self)",
              "called_by": [
                "TranscriptionWorker.__init__",
                "MainWindow.__init__"
              ]
            },
            "load_settings": {
              "doc": "Load settings from file or create default",
              "signature": "(self) -> Dict[str, Any]",
              "called_by": [
                "Settings.__init__"
              ]
            },
            "save_settings": {
              "doc": "Save current settings to file",
              "signature": "(self) -> bool",
              "called_by": [
                "Settings.set"
              ]
            },
            "get": {
              "doc": "Get a setting value",
              "calls": [
                "get"
              ],
              "signature": "(self, key: str, default: Any = None) -> Any",
              "called_by": [
                "Settings.get",
                "Settings.get_model_info",
                "Settings.get_whisper_model_path",
                "Settings.detect_available_models"
              ]
            },
            "set": {
              "doc": "Set a setting value and save",
              "calls": [
                "save_settings"
              ],
              "signature": "(self, key: str, value: Any) -> None"
            },
            "get_whisper_model_path": {
              "doc": "Get the path to the Whisper model file",
              "calls": [
                "get"
              ],
              "signature": "(self) -> Optional[Path]"
            },
            "detect_available_models": {
              "doc": "Detect all available Whisper models on the system",
              "calls": [
                "_scan_folder_for_models",
                "get"
              ],
              "signature": "(self) -> Dict[str, Dict[str, Any]]"
            },
            "_scan_folder_for_models": {
              "doc": "Scan a folder for Whisper model files",
              "signature": "(self, folder: Path, source: str) -> Dict[str, Dict[str, Any]]",
              "called_by": [
                "Settings.detect_available_models"
              ]
            },
            "get_model_info": {
              "doc": "Get information about a specific model size",
              "calls": [
                "get"
              ],
              "signature": "(self, model_size: str) -> Dict[str, Any]"
            }
          },
          "class_constants": {
            "DEFAULT_SETTINGS": "collection"
          },
          "doc": "Manages application settings and configuration"
        }
      },
      "call_graph": {}
    },
    "src\\config\\__init__.py": {
      "language": "python",
      "parsed": false
    },
    "src\\input_handling\\file_handler.py": {
      "language": "python",
      "parsed": true,
      "imports": [
        "pathlib",
        "typing"
      ],
      "functions": {},
      "classes": {
        "FileHandler": {
          "methods": {
            "__init__": {
              "signature": "(self)",
              "called_by": [
                "TranscriptionWorker.__init__",
                "MainWindow.__init__"
              ]
            },
            "validate_file": {
              "doc": "Validate a video file.",
              "signature": "(self, file_path: str) -> Tuple[bool, str]",
              "called_by": [
                "FileHandler.add_to_queue"
              ]
            },
            "add_to_queue": {
              "doc": "Add a file to the processing queue.",
              "calls": [
                "validate_file"
              ],
              "signature": "(self, file_path: str) -> bool"
            },
            "clear_queue": {
              "doc": "Clear the processing queue.",
              "signature": "(self)",
              "called_by": [
                "MainWindow.clear_queue"
              ]
            },
            "get_queue_status": {
              "doc": "Get current queue status.",
              "signature": "(self) -> dict"
            }
          }
        }
      },
      "call_graph": {}
    },
    "src\\input_handling\\file_validator.py": {
      "language": "python",
      "parsed": false
    },
    "src\\input_handling\\queue_manager.py": {
      "language": "python",
      "parsed": true,
      "imports": [
        "pathlib",
        "typing",
        "dataclasses",
        "enum",
        "threading",
        "logging"
      ],
      "functions": {},
      "classes": {
        "QueueItem": {
          "methods": {},
          "decorators": [
            "dataclass"
          ],
          "properties": [
            "file_path",
            "status",
            "progress",
            "error"
          ]
        },
        "QueueManager": {
          "methods": {
            "__init__": {
              "signature": "(self)",
              "called_by": [
                "TranscriptionWorker.__init__",
                "MainWindow.__init__"
              ]
            },
            "is_processing": {
              "decorators": [
                "property"
              ],
              "signature": "(self) -> bool"
            },
            "current_item": {
              "decorators": [
                "property"
              ],
              "signature": "(self) -> Optional[QueueItem]"
            },
            "queue_size": {
              "decorators": [
                "property"
              ],
              "signature": "(self) -> int"
            },
            "add_file": {
              "doc": "Add a file to the processing queue.",
              "signature": "(self, file_path: str | Path) -> bool"
            },
            "get_next_file": {
              "doc": "Get the next file to process.",
              "signature": "(self) -> Optional[QueueItem]"
            },
            "update_progress": {
              "doc": "Update progress for a specific file.",
              "signature": "(self, file_path: Path, progress: float)"
            },
            "mark_completed": {
              "doc": "Mark a file as completed.",
              "signature": "(self, file_path: Path)"
            },
            "mark_failed": {
              "doc": "Mark a file as failed with error message.",
              "signature": "(self, file_path: Path, error: str)"
            },
            "clear_queue": {
              "doc": "Clear all items from the queue.",
              "signature": "(self)",
              "called_by": [
                "MainWindow.clear_queue"
              ]
            },
            "get_queue_status": {
              "doc": "Get status of all files in queue.",
              "signature": "(self) -> List[dict]"
            },
            "start_processing": {
              "doc": "Mark queue as processing.",
              "signature": "(self)"
            },
            "stop_processing": {
              "doc": "Mark queue as stopped.",
              "signature": "(self)"
            }
          }
        }
      },
      "call_graph": {},
      "enums": {
        "FileStatus": {
          "values": [
            "QUEUED",
            "PROCESSING",
            "COMPLETED",
            "FAILED"
          ],
          "doc": ""
        }
      }
    },
    "src\\input_handling\\__init__.py": {
      "language": "python",
      "parsed": false
    },
    "src\\post_processing\\advanced_text_processor.py": {
      "language": "python",
      "parsed": true,
      "imports": [
        "re",
        "typing",
        "logging"
      ],
      "functions": {},
      "classes": {
        "AdvancedTextProcessor": {
          "methods": {
            "__init__": {
              "signature": "(self, remove_fillers: bool = True, aggressive_cleaning: bool = True)",
              "called_by": [
                "TranscriptionWorker.__init__",
                "MainWindow.__init__"
              ]
            },
            "process_transcript": {
              "calls": [
                "_add_smart_punctuation",
                "_basic_cleaning",
                "_create_paragraphs",
                "_final_polish",
                "_fix_capitalization",
                "_fix_sentence_structure",
                "_remove_filler_words"
              ],
              "signature": "(self, text: str) -> str"
            },
            "_basic_cleaning": {
              "signature": "(self, text: str) -> str",
              "called_by": [
                "AdvancedTextProcessor.process_transcript"
              ]
            },
            "_remove_filler_words": {
              "signature": "(self, text: str) -> str",
              "called_by": [
                "AdvancedTextProcessor.process_transcript"
              ]
            },
            "_fix_sentence_structure": {
              "signature": "(self, text: str) -> str",
              "called_by": [
                "AdvancedTextProcessor.process_transcript"
              ]
            },
            "_add_smart_punctuation": {
              "calls": [
                "_add_commas"
              ],
              "signature": "(self, text: str) -> str",
              "called_by": [
                "AdvancedTextProcessor.process_transcript"
              ]
            },
            "_add_commas": {
              "signature": "(self, text: str) -> str",
              "called_by": [
                "AdvancedTextProcessor._add_smart_punctuation"
              ]
            },
            "_fix_capitalization": {
              "signature": "(self, text: str) -> str",
              "called_by": [
                "AdvancedTextProcessor.process_transcript"
              ]
            },
            "_create_paragraphs": {
              "signature": "(self, text: str) -> str",
              "called_by": [
                "AdvancedTextProcessor.process_transcript"
              ]
            },
            "_final_polish": {
              "signature": "(self, text: str) -> str",
              "called_by": [
                "AdvancedTextProcessor.process_transcript"
              ]
            }
          },
          "properties": [
            "remove_fillers",
            "aggressive_cleaning",
            "text"
          ]
        }
      },
      "call_graph": {}
    },
    "src\\post_processing\\combiner.py": {
      "language": "python",
      "parsed": true,
      "imports": [
        "re",
        "difflib",
        "typing",
        "logging"
      ],
      "functions": {},
      "classes": {
        "TextCombiner": {
          "methods": {
            "__init__": {
              "signature": "(self, min_overlap_words: int = 3, similarity_threshold: float = 0.8)",
              "called_by": [
                "TranscriptionWorker.__init__",
                "MainWindow.__init__"
              ]
            },
            "combine_overlapping_segments": {
              "calls": [
                "_log_deduplication_stats",
                "_merge_segments_with_overlap_removal",
                "_simple_append"
              ],
              "signature": "(self, segments: List[str], segment_metadata: Optional[List[Dict[str, Any]]] = None, overlap_seconds: float = 2.5) -> str"
            },
            "_merge_segments_with_overlap_removal": {
              "calls": [
                "_calculate_text_similarity",
                "_simple_append",
                "_smart_concatenate"
              ],
              "signature": "(self, text1: str, text2: str, segment_index: int = 0) -> str",
              "called_by": [
                "TextCombiner.combine_overlapping_segments"
              ]
            },
            "_calculate_text_similarity": {
              "calls": [
                "_normalize_text_for_comparison"
              ],
              "signature": "(self, text1: str, text2: str) -> float",
              "called_by": [
                "TextCombiner._merge_segments_with_overlap_removal"
              ]
            },
            "_normalize_text_for_comparison": {
              "signature": "(self, text: str) -> str",
              "called_by": [
                "TextCombiner._calculate_text_similarity"
              ]
            },
            "_smart_concatenate": {
              "signature": "(self, text1: str, text2: str) -> str",
              "called_by": [
                "TextCombiner._merge_segments_with_overlap_removal"
              ]
            },
            "_should_add_sentence_break": "(self, text1: str, text2: str) -> bool",
            "_simple_append": {
              "signature": "(self, text1: str, text2: str) -> str",
              "called_by": [
                "TextCombiner._merge_segments_with_overlap_removal",
                "TextCombiner.combine_overlapping_segments"
              ]
            },
            "_log_deduplication_stats": {
              "doc": "Log statistics about the deduplication process.",
              "signature": "(self)",
              "called_by": [
                "TextCombiner.combine_overlapping_segments"
              ]
            },
            "get_deduplication_stats": "(self) -> Dict[str, Any]"
          },
          "properties": [
            "min_overlap_words",
            "similarity_threshold",
            "segments",
            "segment_metadata",
            "overlap_seconds",
            "str",
            "text1",
            "text2",
            "segment_index",
            "str",
            "text1",
            "text2",
            "float",
            "text",
            "str",
            "text1",
            "text2",
            "str",
            "text1",
            "text2",
            "bool",
            "text1",
            "text2",
            "str"
          ]
        }
      },
      "call_graph": {}
    },
    "src\\post_processing\\exporter.py": {
      "language": "python",
      "parsed": false
    },
    "src\\post_processing\\text_processor.py": {
      "language": "python",
      "parsed": true,
      "imports": [
        "re",
        "typing",
        "logging"
      ],
      "functions": {},
      "classes": {
        "TextProcessor": {
          "methods": {
            "__init__": {
              "signature": "(self)",
              "called_by": [
                "TranscriptionWorker.__init__",
                "MainWindow.__init__"
              ]
            },
            "split_into_chunks": {
              "doc": "Split long text into manageable chunks at sentence boundaries.",
              "signature": "(self, text: str) -> List[str]",
              "called_by": [
                "TextProcessor.process_transcript"
              ]
            },
            "detect_formatting_break": {
              "signature": "(self, text: str) -> Tuple[str, str]",
              "called_by": [
                "TextProcessor.process_transcript"
              ]
            },
            "format_text": {
              "signature": "(self, text: str) -> str",
              "called_by": [
                "TextProcessor.process_transcript"
              ]
            },
            "process_transcript": {
              "calls": [
                "detect_formatting_break",
                "format_text",
                "split_into_chunks"
              ],
              "signature": "(self, text: str) -> str"
            }
          }
        }
      },
      "call_graph": {}
    },
    "src\\post_processing\\__init__.py": {
      "language": "python",
      "parsed": false
    },
    "src\\subtitles\\smart_timing_estimator.py": {
      "language": "python",
      "parsed": true,
      "imports": [
        "typing",
        "logging",
        "re"
      ],
      "functions": {},
      "classes": {
        "SmartTimingEstimator": {
          "methods": {
            "__init__": {
              "signature": "(self, avg_speech_rate_wpm: int = 140, # Average Spanish speech rate reading_rate_wpm: int = 160, # Subtitle reading rate two_line_extension: float = 0.6, # Extra time for two-line subtitles min_subtitle_duration: float = 1.5, max_subtitle_duration: float = 7.0)",
              "called_by": [
                "TranscriptionWorker.__init__",
                "MainWindow.__init__"
              ]
            },
            "fix_subtitle_timing_without_words": "(self, segments: List[Dict]) -> List[Dict]",
            "estimate_phrase_boundaries": "(self, text: str) -> List[int]",
            "smart_segment_merge": "(self, segments: List[Dict]) -> List[Dict]"
          },
          "doc": "Estimates subtitle timing based on text analysis and speech patterns.",
          "properties": [
            "avg_speech_rate_wpm",
            "reading_rate_wpm",
            "two_line_extension",
            "min_subtitle_duration",
            "max_subtitle_duration",
            "segments",
            "text",
            "segments"
          ]
        }
      },
      "call_graph": {}
    },
    "src\\subtitles\\subtitle_generator.py": {
      "language": "python",
      "parsed": true,
      "imports": [
        "pysubs2",
        "pathlib",
        "typing",
        "logging",
        "re",
        "math",
        "src.subtitles.word_level_analyzer",
        "src.subtitles.subtitle_timing_fixer",
        "src.subtitles.smart_timing_estimator",
        "src.subtitles.word_based_subtitle_generator",
        "src.audio_processing.vad_manager"
      ],
      "functions": {},
      "classes": {
        "SubtitleGenerator": {
          "methods": {
            "__init__": {
              "signature": "(self, max_chars_per_line: int = 42, max_lines_per_subtitle: int = 2, use_word_level_optimization: bool = True, transition_delay: float = 0.15)",
              "called_by": [
                "TranscriptionWorker.__init__",
                "MainWindow.__init__"
              ]
            },
            "generate_subtitles": {
              "calls": [
                "_split_text_for_subtitles"
              ],
              "signature": "(self, segments: List[Dict], output_path: Path, format: str = 'srt', time_offset: float = 0.0, min_duration: float = 0.5, max_duration: float = 7.0, global_sync_offset: float = 0.0) -> Path",
              "called_by": [
                "SubtitleGenerator.generate_multiple_formats"
              ]
            },
            "_split_text_for_subtitles": {
              "calls": [
                "_format_subtitle_text"
              ],
              "signature": "(self, text: str) -> List[str]",
              "called_by": [
                "SubtitleGenerator.generate_subtitles"
              ]
            },
            "_format_subtitle_text": {
              "signature": "(self, text: str) -> str",
              "called_by": [
                "WordBasedSubtitleGenerator.generate_from_segments",
                "SubtitleGenerator._split_text_for_subtitles"
              ]
            },
            "generate_multiple_formats": {
              "calls": [
                "generate_subtitles"
              ],
              "signature": "(self, segments: List[Dict], output_base_path: Path, formats: List[str], **kwargs) -> Dict[str, Path]"
            },
            "adjust_timing": "(self, segments: List[Dict], offset: float = 0.0, speed_factor: float = 1.0) -> List[Dict]",
            "merge_short_segments": "(self, segments: List[Dict], min_duration: float = 1.0) -> List[Dict]",
            "detect_sync_offset": "(self, audio_path: Path, segments: List[Dict]) -> float",
            "get_format_info": {
              "decorators": [
                "staticmethod"
              ],
              "signature": "(format: str) -> Dict[str, str]"
            },
            "configure_word_optimization": "(self, enabled: bool = True, transition_delay: float = 0.15, pause_threshold: float = 0.3, min_pause_for_boundary: float = 0.2)",
            "get_optimization_status": "(self) -> Dict"
          },
          "class_constants": {
            "SUPPORTED_FORMATS": "collection"
          },
          "doc": "Generate subtitle files in various formats from transcription segments.",
          "properties": [
            "max_chars_per_line",
            "max_lines_per_subtitle",
            "use_word_level_optimization",
            "transition_delay",
            "segments",
            "output_path",
            "format",
            "time_offset",
            "min_duration",
            "max_duration",
            "global_sync_offset",
            "text",
            "text",
            "segments",
            "output_base_path",
            "formats",
            "segments",
            "offset",
            "speed_factor",
            "segments",
            "min_duration",
            "audio_path",
            "segments",
            "format",
            "enabled",
            "transition_delay",
            "pause_threshold",
            "min_pause_for_boundary"
          ]
        }
      },
      "call_graph": {}
    },
    "src\\subtitles\\subtitle_timing_fixer.py": {
      "language": "python",
      "parsed": true,
      "imports": [
        "typing",
        "logging"
      ],
      "functions": {},
      "classes": {
        "SubtitleTimingFixer": {
          "methods": {
            "__init__": {
              "signature": "(self, min_display_time: float = 1.5, reading_speed_wpm: int = 160, speech_overlap_buffer: float = 0.5)",
              "called_by": [
                "TranscriptionWorker.__init__",
                "MainWindow.__init__"
              ]
            },
            "fix_subtitle_timing": "(self, segments: List[Dict]) -> List[Dict]",
            "calculate_optimal_split_point": "(self, text: str, max_chars_per_line: int = 42) -> Optional[int]",
            "ensure_speech_coverage": "(self, segment: Dict) -> Dict"
          },
          "doc": "Fixes subtitle timing to ensure they remain visible while being spoken.",
          "properties": [
            "min_display_time",
            "reading_speed_wpm",
            "speech_overlap_buffer",
            "Solution",
            "segments",
            "text",
            "max_chars_per_line",
            "segment"
          ]
        }
      },
      "call_graph": {}
    },
    "src\\subtitles\\word_based_subtitle_generator.py": {
      "language": "python",
      "parsed": true,
      "imports": [
        "pathlib",
        "typing",
        "pysubs2",
        "logging"
      ],
      "functions": {},
      "classes": {
        "WordBasedSubtitleGenerator": {
          "methods": {
            "__init__": {
              "signature": "(self, max_chars_per_line: int = 42, max_words_per_subtitle: int = 10, min_subtitle_duration: float = 1.0, max_subtitle_duration: float = 7.0)",
              "called_by": [
                "TranscriptionWorker.__init__",
                "MainWindow.__init__"
              ]
            },
            "generate_from_segments": {
              "calls": [
                "_format_subtitle_text",
                "_group_words_into_subtitles"
              ],
              "signature": "(self, segments: List[Dict], output_path: Path, format: str = 'srt') -> Path"
            },
            "_group_words_into_subtitles": {
              "signature": "(self, words: List[Dict]) -> List[Dict]",
              "called_by": [
                "WordBasedSubtitleGenerator.generate_from_segments"
              ]
            },
            "_format_subtitle_text": {
              "signature": "(self, text: str) -> str",
              "called_by": [
                "WordBasedSubtitleGenerator.generate_from_segments",
                "SubtitleGenerator._split_text_for_subtitles"
              ]
            }
          },
          "doc": "Generate subtitles using actual word-level timestamps.",
          "properties": [
            "max_chars_per_line",
            "max_words_per_subtitle",
            "min_subtitle_duration",
            "max_subtitle_duration",
            "segments",
            "output_path",
            "format",
            "words",
            "text"
          ]
        }
      },
      "call_graph": {}
    },
    "src\\subtitles\\word_level_analyzer.py": {
      "language": "python",
      "parsed": true,
      "imports": [
        "typing",
        "logging",
        "math"
      ],
      "functions": {},
      "classes": {
        "WordLevelAnalyzer": {
          "methods": {
            "__init__": {
              "signature": "(self, pause_threshold: float = 0.3, min_pause_for_boundary: float = 0.2, transition_delay: float = 0.15, max_segment_duration: float = 7.0, min_segment_duration: float = 1.0, aggressive_merge: bool = True, merge_orphan_words: bool = True)",
              "called_by": [
                "TranscriptionWorker.__init__",
                "MainWindow.__init__"
              ]
            },
            "optimize_segment_boundaries": {
              "calls": [
                "_apply_transition_delay",
                "_ensure_proper_timing",
                "_merge_orphan_segments",
                "_optimize_segment_pair"
              ],
              "signature": "(self, segments: List[Dict]) -> List[Dict]"
            },
            "_optimize_segment_pair": {
              "calls": [
                "_apply_transition_delay",
                "_find_best_pause_near_boundary",
                "_find_pause_points",
                "_split_words_at_time"
              ],
              "signature": "(self, current: Dict, next_segment: Dict) -> Dict",
              "called_by": [
                "WordLevelAnalyzer.optimize_segment_boundaries"
              ]
            },
            "_find_pause_points": {
              "signature": "(self, words: List[Dict]) -> List[Dict]",
              "called_by": [
                "WordLevelAnalyzer._optimize_segment_pair"
              ]
            },
            "_find_best_pause_near_boundary": {
              "signature": "(self, pause_points: List[Dict], current_boundary: float, segment_start: float) -> Optional[Dict]",
              "called_by": [
                "WordLevelAnalyzer._optimize_segment_pair"
              ]
            },
            "_split_words_at_time": {
              "signature": "(self, words: List[Dict], split_time: float) -> Tuple[List[Dict], List[Dict]]",
              "called_by": [
                "WordLevelAnalyzer._optimize_segment_pair"
              ]
            },
            "_apply_transition_delay": {
              "signature": "(self, segment: Dict) -> Dict",
              "called_by": [
                "WordLevelAnalyzer.optimize_segment_boundaries",
                "WordLevelAnalyzer._optimize_segment_pair"
              ]
            },
            "_ensure_proper_timing": {
              "signature": "(self, segments: List[Dict]) -> List[Dict]",
              "called_by": [
                "WordLevelAnalyzer.optimize_segment_boundaries"
              ]
            },
            "analyze_speech_rhythm": "(self, segments: List[Dict]) -> Dict",
            "_merge_orphan_segments": {
              "signature": "(self, segments: List[Dict]) -> List[Dict]",
              "called_by": [
                "WordLevelAnalyzer.optimize_segment_boundaries"
              ]
            }
          },
          "doc": "Analyzes word-level timestamps to create natural subtitle boundaries.",
          "properties": [
            "pause_threshold",
            "min_pause_for_boundary",
            "transition_delay",
            "max_segment_duration",
            "min_segment_duration",
            "aggressive_merge",
            "merge_orphan_words",
            "segments",
            "current",
            "next_segment",
            "words",
            "pause_points",
            "current_boundary",
            "segment_start",
            "words",
            "split_time",
            "segment",
            "segments",
            "segments",
            "segments"
          ]
        }
      },
      "call_graph": {}
    },
    "src\\subtitles\\__init__.py": {
      "language": "python",
      "parsed": false
    },
    "src\\transcription\\enhanced_whisper_manager.py": {
      "language": "python",
      "parsed": true,
      "imports": [
        "os",
        "pathlib",
        "typing",
        "faster_whisper",
        "torch",
        "time",
        "logging",
        "datetime",
        "tempfile",
        "pydub",
        "src.audio_processing.vad_manager"
      ],
      "functions": {},
      "classes": {
        "EnhancedWhisperManager": {
          "methods": {
            "__init__": {
              "calls": [
                "load_model"
              ],
              "signature": "(self, model_size: str = \"large-v2\", model_path: Optional[str] = None, vad_threshold: float = 0.3, # More sensitive detection merge_gap: float = 1.5 # Merge segments within 1.5 seconds for better context)",
              "called_by": [
                "TranscriptionWorker.__init__",
                "MainWindow.__init__"
              ]
            },
            "load_model": {
              "doc": "Load the faster-whisper model into memory.",
              "signature": "(self) -> None",
              "called_by": [
                "WhisperManager.reload_model",
                "WhisperManager.__init__",
                "EnhancedWhisperManager.__init__",
                "WhisperManager.load_model",
                "WhisperManager.transcribe_audio",
                "WhisperManager.transcribe_audio_with_timestamps"
              ]
            },
            "transcribe_with_vad": {
              "calls": [
                "_optimize_segments_for_subtitles",
                "simple_transcribe_with_timestamps"
              ],
              "signature": "(self, audio_path: str | Path, language: str = None, use_vad: bool = True) -> Dict[str, Any]",
              "called_by": [
                "EnhancedWhisperManager.transcribe_audio_with_timestamps"
              ]
            },
            "_optimize_segments_for_subtitles": {
              "signature": "(self, segments: List[Dict]) -> List[Dict]",
              "called_by": [
                "EnhancedWhisperManager.transcribe_with_vad",
                "EnhancedWhisperManager.simple_transcribe_with_timestamps"
              ]
            },
            "transcribe_audio_with_timestamps": {
              "calls": [
                "simple_transcribe_with_timestamps",
                "transcribe_with_vad"
              ],
              "signature": "(self, audio_path: str | Path, language: str = None) -> Dict[str, Any]"
            },
            "simple_transcribe_with_timestamps": {
              "calls": [
                "_optimize_segments_for_subtitles"
              ],
              "signature": "(self, audio_path: str | Path, language: str = None) -> Dict[str, Any]",
              "called_by": [
                "EnhancedWhisperManager.transcribe_with_vad",
                "EnhancedWhisperManager.transcribe_audio_with_timestamps"
              ]
            },
            "transcribe_audio": "(self, audio_path: str | Path, language: str = None) -> Dict[str, Any]",
            "get_model_info": {
              "doc": "Return information about the loaded model.",
              "signature": "(self) -> Dict[str, Any]"
            },
            "get_quick_offset": "(self, audio_path: str | Path) -> float"
          },
          "doc": "Whisper manager using faster-whisper for accurate word-level timestamps.",
          "properties": [
            "model_size",
            "model_path",
            "vad_threshold",
            "merge_gap",
            "audio_path",
            "language",
            "use_vad",
            "segments",
            "audio_path",
            "language",
            "audio_path",
            "language",
            "audio_path",
            "language",
            "audio_path"
          ]
        }
      },
      "call_graph": {}
    },
    "src\\transcription\\progress_tracker.py": {
      "language": "python",
      "parsed": false
    },
    "src\\transcription\\transcriber.py": {
      "language": "python",
      "parsed": false
    },
    "src\\transcription\\transcription_pipeline.py": {
      "language": "python",
      "parsed": true,
      "imports": [
        "pathlib",
        "typing",
        "logging",
        "time",
        "datetime",
        "src.audio_processing.converter",
        "src.transcription.whisper_manager",
        "src.transcription.enhanced_whisper_manager",
        "src.post_processing.text_processor",
        "src.post_processing.advanced_text_processor",
        "src.post_processing.combiner",
        "src.subtitles.subtitle_generator"
      ],
      "functions": {},
      "classes": {
        "TranscriptionPipeline": {
          "methods": {
            "__init__": {
              "signature": "(self, use_advanced_processing: bool = True, model_size: str = \"large\", model_path: Optional[str] = None, use_vad_enhancement: bool = True, # Enable VAD for accurate subtitle timing use_faster_whisper: bool = False # Use faster-whisper for word-level timestamps)",
              "called_by": [
                "TranscriptionWorker.__init__",
                "MainWindow.__init__"
              ]
            },
            "process_video": "(self, video_path: str | Path, output_dir: Optional[Path] = None, progress_callback: Optional[Callable[[float, str], None]] = None, language: Optional[str] = None) -> Dict[str, Any]",
            "process_video_with_subtitles": "(self, video_path: str | Path, output_dir: Optional[Path] = None, progress_callback: Optional[Callable[[float, str], None]] = None, language: Optional[str] = None, subtitle_formats: Optional[List[str]] = None, max_chars_per_line: int = 42) -> Dict[str, Any]",
            "get_pipeline_status": {
              "doc": "Get comprehensive status information about the pipeline components.",
              "signature": "(self) -> Dict[str, Any]"
            },
            "configure_subtitle_sync": "(self, use_word_level: bool = True, transition_delay: float = 0.15, pause_threshold: float = 0.3, min_pause_for_boundary: float = 0.2)"
          },
          "properties": [
            "use_advanced_processing",
            "model_size",
            "model_path",
            "use_vad_enhancement",
            "use_faster_whisper",
            "video_path",
            "output_dir",
            "progress_callback",
            "language",
            "video_path",
            "output_dir",
            "progress_callback",
            "language",
            "subtitle_formats",
            "max_chars_per_line",
            "use_word_level",
            "transition_delay",
            "pause_threshold",
            "min_pause_for_boundary"
          ]
        }
      },
      "call_graph": {}
    },
    "src\\transcription\\whisper_manager.py": {
      "language": "python",
      "parsed": true,
      "imports": [
        "pathlib",
        "typing",
        "whisper",
        "torch",
        "time",
        "logging",
        "datetime",
        "os"
      ],
      "functions": {},
      "classes": {
        "WhisperManager": {
          "methods": {
            "__init__": {
              "calls": [
                "load_model"
              ],
              "signature": "(self, model_size: str = \"large\", model_path: Optional[str] = None)",
              "called_by": [
                "TranscriptionWorker.__init__",
                "MainWindow.__init__"
              ]
            },
            "load_model": {
              "doc": "Load the Whisper model into memory.",
              "calls": [
                "load_model"
              ],
              "signature": "(self) -> None",
              "called_by": [
                "WhisperManager.reload_model",
                "WhisperManager.__init__",
                "EnhancedWhisperManager.__init__",
                "WhisperManager.load_model",
                "WhisperManager.transcribe_audio",
                "WhisperManager.transcribe_audio_with_timestamps"
              ]
            },
            "reload_model": {
              "calls": [
                "load_model"
              ],
              "signature": "(self, model_size: str, model_path: Optional[str] = None) -> None"
            },
            "transcribe_audio_with_timestamps": {
              "calls": [
                "_clean_transcription_text",
                "_optimize_segment_timing",
                "load_model"
              ],
              "signature": "(self, audio_path: str | Path, language: str = None) -> Dict[str, Any]"
            },
            "_optimize_segment_timing": {
              "signature": "(self, segments)",
              "called_by": [
                "WhisperManager.transcribe_audio_with_timestamps"
              ]
            },
            "transcribe_audio": {
              "calls": [
                "_clean_transcription_text",
                "load_model"
              ],
              "signature": "(self, audio_path: str | Path, language: str = None) -> Dict[str, Any]"
            },
            "_detect_excessive_repetition": {
              "signature": "(self, text: str, max_repetitions: int = 3) -> bool",
              "called_by": [
                "WhisperManager._clean_repetitive_text"
              ]
            },
            "_clean_repetitive_text": {
              "calls": [
                "_detect_excessive_repetition"
              ],
              "signature": "(self, text: str, max_repetitions: int = 3) -> str",
              "called_by": [
                "WhisperManager._clean_transcription_text"
              ]
            },
            "_clean_transcription_text": {
              "calls": [
                "_clean_repetitive_text"
              ],
              "signature": "(self, text: str) -> str",
              "called_by": [
                "WhisperManager.transcribe_audio_with_timestamps",
                "WhisperManager.transcribe_audio"
              ]
            },
            "get_model_info": {
              "doc": "Return information about the loaded model.",
              "signature": "(self) -> Dict[str, Any]"
            }
          },
          "properties": [
            "model_size",
            "model_path",
            "model_size",
            "model_path",
            "audio_path",
            "language",
            "segments",
            "audio_path",
            "language",
            "text",
            "max_repetitions",
            "text",
            "max_repetitions",
            "text"
          ]
        }
      },
      "call_graph": {}
    },
    "src\\transcription\\__init__.py": {
      "language": "python",
      "parsed": false
    },
    "src\\translation\\subtitle_translator.py": {
      "language": "python",
      "parsed": true,
      "imports": [
        "logging",
        "pathlib",
        "typing",
        "pysubs2",
        "json",
        "re",
        ".engines.helsinki_translator",
        ".engines.tower_translator",
        "langdetect"
      ],
      "functions": {},
      "classes": {
        "SubtitleTranslator": {
          "methods": {
            "__init__": {
              "calls": [
                "_initialize_translator"
              ],
              "signature": "(self, source_lang: str = \"auto\", target_lang: str = \"en\", use_context: bool = True, context_window: int = 3, prefer_tower: bool = True)",
              "called_by": [
                "TranscriptionWorker.__init__",
                "MainWindow.__init__"
              ]
            },
            "_initialize_translator": {
              "doc": "Initialize the translation engine with smart selection for PT->EN.",
              "signature": "(self, source_lang: str, target_lang: str)",
              "called_by": [
                "SubtitleTranslator.translate_from_segments_data",
                "SubtitleTranslator.translate_subtitle_file",
                "SubtitleTranslator.__init__"
              ]
            },
            "translate_subtitle_file": {
              "calls": [
                "_detect_language",
                "_generate_output_path",
                "_initialize_translator",
                "create_translated_subtitle",
                "parse_subtitle_file",
                "translate_segments",
                "translate_subtitle_file"
              ],
              "signature": "(self, subtitle_path: Path, output_path: Optional[Path] = None, preserve_original: bool = True) -> Path",
              "called_by": [
                "SubtitleTranslator.translate_subtitle_file"
              ]
            },
            "parse_subtitle_file": {
              "signature": "(self, subtitle_path: Path) -> List[Dict]",
              "called_by": [
                "SubtitleTranslator.translate_subtitle_file"
              ]
            },
            "translate_segments": {
              "calls": [
                "translate_segments"
              ],
              "signature": "(self, segments: List[Dict]) -> List[Dict]",
              "called_by": [
                "SubtitleTranslator.translate_from_segments_data",
                "SubtitleTranslator.translate_subtitle_file",
                "SubtitleTranslator.translate_segments"
              ]
            },
            "create_translated_subtitle": {
              "signature": "(self, translated_segments: List[Dict], original_path: Path, output_path: Path)",
              "called_by": [
                "SubtitleTranslator.translate_subtitle_file"
              ]
            },
            "translate_from_segments_data": {
              "calls": [
                "_detect_language",
                "_initialize_translator",
                "translate_segments"
              ],
              "signature": "(self, segments: List[Dict], output_path: Path, subtitle_format: str = 'srt') -> Path"
            },
            "_detect_language": {
              "signature": "(self, segments: List[Dict]) -> Optional[str]",
              "called_by": [
                "SubtitleTranslator.translate_from_segments_data",
                "SubtitleTranslator.translate_subtitle_file"
              ]
            },
            "_generate_output_path": {
              "signature": "(self, input_path: Path) -> Path",
              "called_by": [
                "SubtitleTranslator.translate_subtitle_file"
              ]
            },
            "get_supported_languages": {
              "doc": "Get list of supported language pairs.",
              "calls": [
                "get_supported_languages"
              ],
              "signature": "(self) -> Dict",
              "called_by": [
                "SubtitleTranslator.get_supported_languages"
              ]
            },
            "cleanup": {
              "doc": "Clean up resources.",
              "calls": [
                "cleanup"
              ],
              "signature": "(self)",
              "called_by": [
                "SubtitleTranslator.cleanup"
              ]
            },
            "get_translator_info": "(self) -> Dict[str, any]"
          },
          "properties": [
            "source_lang",
            "target_lang",
            "use_context",
            "context_window",
            "prefer_tower",
            "subtitle_path",
            "output_path",
            "preserve_original",
            "subtitle_path",
            "segments",
            "translated_segments",
            "original_path",
            "output_path",
            "segments",
            "output_path",
            "subtitle_format",
            "segments",
            "input_path"
          ]
        }
      },
      "call_graph": {}
    },
    "src\\translation\\__init__.py": {
      "language": "python",
      "parsed": false
    },
    "src\\ui\\main_window.py": {
      "language": "python",
      "parsed": true,
      "imports": [
        "PyQt6.QtWidgets",
        "PyQt6.QtCore",
        "PyQt6.QtGui",
        "pathlib",
        "src.transcription.transcription_pipeline",
        "src.input_handling.queue_manager",
        "src.ui.worker",
        "src.ui.styles.modern_theme",
        "src.config.settings",
        "logging",
        "time",
        "datetime",
        "src.translation.engines.tower_translator"
      ],
      "functions": {},
      "classes": {
        "MainWindow": {
          "methods": {
            "__init__": {
              "calls": [
                "__init__",
                "init_ui"
              ],
              "signature": "(self)",
              "called_by": [
                "TranscriptionWorker.__init__",
                "MainWindow.__init__"
              ]
            },
            "init_ui": {
              "doc": "Initialize flat, modern UI layout",
              "calls": [
                "check_translation_engine",
                "on_language_changed",
                "update_model_status"
              ],
              "signature": "(self)",
              "called_by": [
                "MainWindow.__init__"
              ]
            },
            "closeEvent": {
              "doc": "Handle application closure with proper thread cleanup.",
              "signature": "(self, event)"
            },
            "lazy_init_pipeline": {
              "doc": "Lazily initialize the transcription pipeline when needed.",
              "signature": "(self)",
              "called_by": [
                "MainWindow.start_processing"
              ]
            },
            "update_time_estimate": {
              "doc": "Update the estimated time remaining with enhanced accuracy.",
              "signature": "(self)"
            },
            "update_progress": {
              "doc": "Update progress with enhanced status reporting.",
              "signature": "(self, progress: float, status: str)"
            },
            "start_processing": {
              "doc": "Start processing with enhanced error handling and status reporting.",
              "calls": [
                "get_selected_subtitle_formats",
                "get_translation_settings",
                "handle_error",
                "lazy_init_pipeline"
              ],
              "signature": "(self)"
            },
            "handle_file_completed": {
              "doc": "Handle completion of a single file with enhanced reporting.",
              "signature": "(self, result)"
            },
            "handle_all_completed": {
              "doc": "Handle completion of all files with final cleanup.",
              "signature": "(self)"
            },
            "handle_error": {
              "doc": "Handle processing error with enhanced error reporting.",
              "signature": "(self, file_path, error_msg)",
              "called_by": [
                "MainWindow.start_processing"
              ]
            },
            "add_files": {
              "doc": "Add individual files to the queue with enhanced feedback.",
              "calls": [
                "update_start_button"
              ],
              "signature": "(self)"
            },
            "add_directory": {
              "doc": "Add all video files from a directory with enhanced feedback.",
              "calls": [
                "update_start_button"
              ],
              "signature": "(self)"
            },
            "select_output_dir": {
              "doc": "Select output directory for transcripts.",
              "calls": [
                "update_start_button"
              ],
              "signature": "(self)"
            },
            "clear_queue": {
              "doc": "Clear the processing queue with confirmation.",
              "calls": [
                "clear_queue",
                "update_start_button"
              ],
              "signature": "(self)",
              "called_by": [
                "MainWindow.clear_queue"
              ]
            },
            "update_start_button": {
              "doc": "Update start button state based on queue and output directory.",
              "signature": "(self)",
              "called_by": [
                "MainWindow.clear_queue",
                "MainWindow.add_directory",
                "MainWindow.add_files",
                "MainWindow.select_output_dir"
              ]
            },
            "toggle_pause": {
              "doc": "Pause or resume processing with enhanced status reporting.",
              "signature": "(self)"
            },
            "load_model_folder": {
              "doc": "Open dialog to select a folder containing Whisper models.",
              "calls": [
                "update_model_status"
              ],
              "signature": "(self)"
            },
            "on_model_size_changed": {
              "doc": "Handle model size selection change.",
              "calls": [
                "update_model_status"
              ],
              "signature": "(self, model_size: str)"
            },
            "on_subtitle_export_changed": {
              "doc": "Handle subtitle export checkbox toggle.",
              "signature": "(self, state)"
            },
            "on_faster_whisper_changed": {
              "doc": "Handle faster-whisper checkbox toggle.",
              "signature": "(self, state)"
            },
            "on_translate_changed": {
              "doc": "Handle translation checkbox toggle.",
              "calls": [
                "check_translation_engine"
              ],
              "signature": "(self, state)"
            },
            "check_translation_engine": {
              "doc": "Check and display which translation engine will be used.",
              "signature": "(self)",
              "called_by": [
                "MainWindow.init_ui",
                "MainWindow.on_translate_changed"
              ]
            },
            "get_selected_subtitle_formats": {
              "doc": "Get list of selected subtitle formats.",
              "signature": "(self)",
              "called_by": [
                "MainWindow.start_processing"
              ]
            },
            "get_translation_settings": {
              "doc": "Get translation settings if enabled.",
              "signature": "(self)",
              "called_by": [
                "MainWindow.start_processing"
              ]
            },
            "on_language_changed": {
              "doc": "Handle language selection change.",
              "signature": "(self, language_selection: str)",
              "called_by": [
                "MainWindow.init_ui"
              ]
            },
            "update_model_status": {
              "doc": "Update the model status label based on available models.",
              "signature": "(self)",
              "called_by": [
                "MainWindow.init_ui",
                "MainWindow.on_model_size_changed",
                "MainWindow.load_model_folder"
              ]
            }
          },
          "inherits": [
            "QMainWindow"
          ],
          "properties": [
            "color",
            "padding",
            "border",
            "color",
            "padding",
            "border",
            "border",
            "padding",
            "QComboBox",
            "border",
            "QComboBox",
            "image",
            "color",
            "padding",
            "border",
            "padding",
            "QComboBox",
            "border",
            "QComboBox",
            "image",
            "color",
            "padding",
            "QCheckBox",
            "width",
            "height",
            "border",
            "QCheckBox",
            "color",
            "padding",
            "QCheckBox",
            "width",
            "height",
            "border",
            "QCheckBox",
            "color",
            "color",
            "QCheckBox",
            "width",
            "height",
            "color",
            "border",
            "padding",
            "color",
            "padding",
            "QCheckBox",
            "width",
            "height",
            "border",
            "background",
            "QCheckBox",
            "background",
            "background",
            "border",
            "padding",
            "color",
            "QComboBox",
            "QComboBox",
            "border",
            "QComboBox",
            "image",
            "color",
            "padding",
            "background",
            "color",
            "border",
            "QListWidget",
            "padding",
            "QListWidget",
            "color",
            "padding",
            "border",
            "QPushButton",
            "QPushButton",
            "color",
            "color",
            "padding",
            "QPushButton",
            "color",
            "padding",
            "background",
            "color",
            "padding",
            "background",
            "color",
            "padding",
            "background",
            "color",
            "padding",
            "background",
            "color",
            "padding",
            "border",
            "color",
            "padding",
            "border"
          ]
        }
      },
      "call_graph": {}
    },
    "src\\ui\\main_window_old.py": {
      "language": "python",
      "parsed": true,
      "imports": [
        "PyQt6.QtCore",
        "PyQt6.QtGui",
        "pathlib",
        "src.transcription.transcription_pipeline",
        "src.input_handling.queue_manager",
        "src.ui.worker",
        "src.ui.styles.modern_theme",
        "logging",
        "time",
        "datetime"
      ],
      "functions": {},
      "classes": {
        "MainWindow": {
          "methods": {
            "__init__": {
              "calls": [
                "__init__",
                "init_ui"
              ],
              "signature": "(self)",
              "called_by": [
                "TranscriptionWorker.__init__",
                "MainWindow.__init__"
              ]
            },
            "init_ui": {
              "doc": "Initialize the user interface with modern Material Design.",
              "signature": "(self)",
              "called_by": [
                "MainWindow.__init__"
              ]
            },
            "closeEvent": {
              "doc": "Handle application closure with proper thread cleanup.",
              "signature": "(self, event)"
            },
            "lazy_init_pipeline": {
              "doc": "Lazily initialize the transcription pipeline when needed.",
              "signature": "(self)",
              "called_by": [
                "MainWindow.start_processing"
              ]
            },
            "update_time_estimate": {
              "doc": "Update the estimated time remaining with enhanced accuracy.",
              "signature": "(self)"
            },
            "update_progress": {
              "doc": "Update progress with enhanced status reporting.",
              "signature": "(self, progress: float, status: str)"
            },
            "start_processing": {
              "doc": "Start processing with enhanced error handling and status reporting.",
              "calls": [
                "handle_error",
                "lazy_init_pipeline"
              ],
              "signature": "(self)"
            },
            "handle_file_completed": {
              "doc": "Handle completion of a single file with enhanced reporting.",
              "signature": "(self, result)"
            },
            "handle_all_completed": {
              "doc": "Handle completion of all files with final cleanup.",
              "signature": "(self)"
            },
            "handle_error": {
              "doc": "Handle processing error with enhanced error reporting.",
              "signature": "(self, file_path, error_msg)",
              "called_by": [
                "MainWindow.start_processing"
              ]
            },
            "add_files": {
              "doc": "Add individual files to the queue with enhanced feedback.",
              "calls": [
                "update_start_button"
              ],
              "signature": "(self)"
            },
            "add_directory": {
              "doc": "Add all video files from a directory with enhanced feedback.",
              "calls": [
                "update_start_button"
              ],
              "signature": "(self)"
            },
            "select_output_dir": {
              "doc": "Select output directory for transcripts.",
              "calls": [
                "update_start_button"
              ],
              "signature": "(self)"
            },
            "clear_queue": {
              "doc": "Clear the processing queue with confirmation.",
              "calls": [
                "clear_queue",
                "update_start_button"
              ],
              "signature": "(self)",
              "called_by": [
                "MainWindow.clear_queue"
              ]
            },
            "update_start_button": {
              "doc": "Update start button state based on queue and output directory.",
              "signature": "(self)",
              "called_by": [
                "MainWindow.clear_queue",
                "MainWindow.add_directory",
                "MainWindow.add_files",
                "MainWindow.select_output_dir"
              ]
            },
            "toggle_pause": {
              "doc": "Pause or resume processing with enhanced status reporting.",
              "signature": "(self)"
            }
          },
          "inherits": [
            "QMainWindow"
          ],
          "properties": [
            "color",
            "color",
            "border",
            "padding",
            "border",
            "padding",
            "color",
            "border",
            "padding",
            "border",
            "padding",
            "color",
            "background",
            "x1",
            "stop",
            "stop",
            "color",
            "padding",
            "QPushButton",
            "background",
            "x1",
            "stop",
            "stop",
            "QPushButton",
            "color",
            "color",
            "padding",
            "QPushButton"
          ]
        }
      },
      "call_graph": {}
    },
    "src\\ui\\progress_widget.py": {
      "language": "python",
      "parsed": false
    },
    "src\\ui\\queue_widget.py": {
      "language": "python",
      "parsed": false
    },
    "src\\ui\\upload_widget.py": {
      "language": "python",
      "parsed": false
    },
    "src\\ui\\worker.py": {
      "language": "python",
      "parsed": true,
      "imports": [
        "PyQt6.QtCore",
        "pathlib",
        "time",
        "logging",
        "datetime",
        "src.translation.subtitle_translator",
        "sys",
        "traceback",
        "src.translation.subtitle_translator",
        "traceback",
        "traceback",
        "traceback"
      ],
      "functions": {},
      "classes": {
        "TranscriptionWorker": {
          "methods": {
            "__init__": {
              "calls": [
                "__init__"
              ],
              "signature": "(self, pipeline, queue_manager, output_dir, language_code=None, subtitle_formats=None, max_chars_per_line=42, translation_settings=None)",
              "called_by": [
                "TranscriptionWorker.__init__",
                "MainWindow.__init__"
              ]
            },
            "run": {
              "doc": "Main processing loop with enhanced progress reporting.",
              "calls": [
                "_cleanup",
                "progress_callback"
              ],
              "signature": "(self)"
            },
            "progress_callback": {
              "signature": "(progress: float, status: str)",
              "called_by": [
                "TranscriptionWorker.run"
              ]
            },
            "pause": {
              "doc": "Pause processing.",
              "signature": "(self)"
            },
            "resume": {
              "doc": "Resume processing.",
              "signature": "(self)"
            },
            "stop": {
              "doc": "Stop processing gracefully.",
              "signature": "(self)"
            },
            "_cleanup": {
              "doc": "Clean up resources before thread ends.",
              "signature": "(self)",
              "called_by": [
                "TranscriptionWorker.run"
              ]
            },
            "wait_with_timeout": "(self, timeout_ms: int = 5000) -> bool"
          },
          "inherits": [
            "QThread"
          ],
          "properties": [
            "pipeline",
            "queue_manager",
            "output_dir",
            "language_code",
            "subtitle_formats",
            "max_chars_per_line",
            "translation_settings",
            "timeout_ms",
            "bool"
          ]
        }
      },
      "call_graph": {}
    },
    "src\\ui\\__init__.py": {
      "language": "python",
      "parsed": false
    },
    "src\\utils\\error_handler.py": {
      "language": "python",
      "parsed": false
    },
    "src\\utils\\logger.py": {
      "language": "python",
      "parsed": false
    },
    "src\\utils\\__init__.py": {
      "language": "python",
      "parsed": false
    },
    "src\\ui\\styles\\modern_theme.py": {
      "language": "python",
      "parsed": true,
      "functions": {},
      "classes": {
        "ModernTheme": {
          "methods": {
            "get_stylesheet": {
              "decorators": [
                "classmethod"
              ],
              "doc": "Generate the complete PyQt6 stylesheet",
              "signature": "(cls)"
            },
            "get_component_styles": {
              "decorators": [
                "classmethod"
              ],
              "doc": "Get additional component-specific styles",
              "signature": "(cls)"
            }
          },
          "class_constants": {
            "COLORS": "collection",
            "TYPOGRAPHY": "collection",
            "SPACING": "collection",
            "RADIUS": "collection",
            "SHADOWS": "collection"
          },
          "doc": "Modern Material Design 3 inspired theme for the Video Transcriber App",
          "properties": [
            "color",
            "color",
            "border",
            "padding",
            "margin",
            "color",
            "border",
            "padding",
            "QPushButton",
            "QPushButton",
            "QPushButton",
            "color",
            "color",
            "border",
            "color",
            "color",
            "border",
            "height",
            "QProgressBar",
            "background",
            "x1",
            "stop",
            "stop",
            "border",
            "padding",
            "outline",
            "QListWidget",
            "border",
            "padding",
            "margin",
            "color",
            "QListWidget",
            "QListWidget",
            "color",
            "color",
            "color",
            "color",
            "border",
            "padding",
            "color",
            "QLineEdit",
            "QLineEdit",
            "color",
            "border",
            "padding",
            "color",
            "QComboBox",
            "QComboBox",
            "border",
            "QComboBox",
            "image",
            "QScrollBar",
            "width",
            "QScrollBar",
            "QScrollBar",
            "QScrollBar",
            "QScrollBar",
            "border",
            "background",
            "height",
            "QTabWidget",
            "border",
            "QTabBar",
            "color",
            "padding",
            "QTabBar",
            "color",
            "QTabBar",
            "padding",
            "QMenuBar",
            "padding",
            "color",
            "QMenuBar",
            "border",
            "padding",
            "QMenu",
            "padding",
            "QMenu",
            "color",
            "color",
            "padding",
            "color",
            "border",
            "padding",
            "border",
            "padding",
            "margin",
            "color",
            "border",
            "QGroupBox",
            "left",
            "padding",
            "color",
            "border",
            "padding",
            "color",
            "border",
            "padding",
            "color",
            "border",
            "padding",
            "border",
            "padding",
            "margin"
          ]
        }
      },
      "call_graph": {}
    },
    "src\\translation\\engines\\helsinki_translator.py": {
      "language": "python",
      "parsed": true,
      "imports": [
        "logging",
        "re",
        "typing",
        "pathlib",
        "transformers",
        "torch",
        "torch"
      ],
      "functions": {},
      "classes": {
        "HelsinkiTranslator": {
          "methods": {
            "__init__": {
              "calls": [
                "_initialize_model"
              ],
              "signature": "(self, source_lang: str, target_lang: str, device: str = \"cpu\")",
              "called_by": [
                "TranscriptionWorker.__init__",
                "MainWindow.__init__"
              ]
            },
            "_initialize_model": {
              "doc": "Load the appropriate Helsinki-NLP model.",
              "calls": [
                "_get_model_name",
                "_initialize_model"
              ],
              "signature": "(self)",
              "called_by": [
                "TowerTranslator.__init__",
                "HelsinkiTranslator.__init__",
                "HelsinkiTranslator._initialize_model"
              ]
            },
            "_get_model_name": {
              "doc": "Get the model name for the language pair.",
              "signature": "(self) -> Optional[str]",
              "called_by": [
                "HelsinkiTranslator._initialize_model"
              ]
            },
            "translate": {
              "signature": "(self, text: str) -> str",
              "called_by": [
                "HelsinkiTranslator.batch_translate",
                "HelsinkiTranslator.translate_with_context_fixed",
                "TowerTranslator.translate_with_context",
                "TowerTranslator.translate_segments",
                "TowerTranslator.batch_translate",
                "HelsinkiTranslator.translate_with_sliding_context",
                "HelsinkiTranslator.translate_with_context",
                "HelsinkiTranslator.translate_segments_with_smart_context",
                "HelsinkiTranslator.translate_segments"
              ]
            },
            "translate_segments": {
              "calls": [
                "translate"
              ],
              "signature": "(self, segments: List[Dict]) -> List[Dict]",
              "called_by": [
                "SubtitleTranslator.translate_from_segments_data",
                "SubtitleTranslator.translate_subtitle_file",
                "SubtitleTranslator.translate_segments"
              ]
            },
            "translate_with_context": {
              "calls": [
                "_extract_current_from_context",
                "translate"
              ],
              "signature": "(self, segments: List[Dict], context_window: int = 3) -> List[Dict]"
            },
            "_extract_current_from_context": {
              "signature": "(self, translated_context: str) -> str",
              "called_by": [
                "HelsinkiTranslator.translate_with_context"
              ]
            },
            "translate_with_context_fixed": {
              "calls": [
                "translate"
              ],
              "signature": "(self, segments: List[Dict], context_window: int = 3) -> List[Dict]"
            },
            "translate_with_sliding_context": {
              "calls": [
                "translate"
              ],
              "signature": "(self, segments: List[Dict], context_window: int = 3) -> List[Dict]"
            },
            "translate_segments_with_smart_context": {
              "calls": [
                "translate"
              ],
              "signature": "(self, segments: List[Dict]) -> List[Dict]"
            },
            "batch_translate": {
              "calls": [
                "translate"
              ],
              "signature": "(self, texts: List[str], batch_size: int = 32) -> List[str]"
            },
            "get_supported_languages": {
              "decorators": [
                "staticmethod"
              ],
              "signature": "() -> Dict[str, List[Tuple[str, str]]]",
              "called_by": [
                "SubtitleTranslator.get_supported_languages"
              ]
            },
            "cleanup": {
              "doc": "Clean up resources.",
              "signature": "(self)",
              "called_by": [
                "SubtitleTranslator.cleanup"
              ]
            }
          },
          "class_constants": {
            "SUPPORTED_PAIRS": "collection"
          },
          "properties": [
            "source_lang",
            "target_lang",
            "device",
            "text",
            "segments",
            "segments",
            "context_window",
            "translated_context",
            "segments",
            "context_window",
            "segments",
            "context_window",
            "segments",
            "texts",
            "batch_size"
          ]
        }
      },
      "call_graph": {}
    },
    "src\\translation\\engines\\tower_translator.py": {
      "language": "python",
      "parsed": true,
      "imports": [
        "logging",
        "re",
        "typing",
        "torch",
        "transformers"
      ],
      "functions": {},
      "classes": {
        "TowerTranslator": {
          "methods": {
            "__init__": {
              "calls": [
                "_check_gpu_availability",
                "_initialize_model"
              ],
              "signature": "(self)",
              "called_by": [
                "TranscriptionWorker.__init__",
                "MainWindow.__init__"
              ]
            },
            "_check_gpu_availability": {
              "signature": "(self)",
              "called_by": [
                "TowerTranslator.__init__"
              ]
            },
            "_initialize_model": {
              "signature": "(self)",
              "called_by": [
                "TowerTranslator.__init__",
                "HelsinkiTranslator.__init__",
                "HelsinkiTranslator._initialize_model"
              ]
            },
            "translate": {
              "signature": "(self, text: str, variant: str = \"brazilian\") -> str",
              "called_by": [
                "HelsinkiTranslator.batch_translate",
                "HelsinkiTranslator.translate_with_context_fixed",
                "TowerTranslator.translate_with_context",
                "TowerTranslator.translate_segments",
                "TowerTranslator.batch_translate",
                "HelsinkiTranslator.translate_with_sliding_context",
                "HelsinkiTranslator.translate_with_context",
                "HelsinkiTranslator.translate_segments_with_smart_context",
                "HelsinkiTranslator.translate_segments"
              ]
            },
            "translate_segments": {
              "calls": [
                "_detect_portuguese_variant",
                "translate"
              ],
              "signature": "(self, segments: List[Dict]) -> List[Dict]",
              "called_by": [
                "SubtitleTranslator.translate_from_segments_data",
                "SubtitleTranslator.translate_subtitle_file",
                "SubtitleTranslator.translate_segments"
              ]
            },
            "translate_with_context": {
              "calls": [
                "_detect_portuguese_variant",
                "translate"
              ],
              "signature": "(self, segments: List[Dict], context_window: int = 2) -> List[Dict]"
            },
            "_detect_portuguese_variant": {
              "signature": "(self, segments: List[Dict]) -> str",
              "called_by": [
                "TowerTranslator.translate_segments",
                "TowerTranslator.translate_with_context"
              ]
            },
            "batch_translate": {
              "calls": [
                "translate"
              ],
              "signature": "(self, texts: List[str], batch_size: int = 8) -> List[str]"
            },
            "cleanup": {
              "doc": "Clean up GPU resources.",
              "signature": "(self)",
              "called_by": [
                "SubtitleTranslator.cleanup"
              ]
            },
            "check_gpu_requirements": {
              "decorators": [
                "staticmethod"
              ],
              "signature": "() -> Dict[str, any]"
            }
          },
          "class_constants": {
            "MODEL_NAME": "str",
            "MIN_VRAM_GB": "number"
          },
          "properties": [
            "text",
            "variant",
            "segments",
            "segments",
            "context_window",
            "segments",
            "texts",
            "batch_size"
          ]
        }
      },
      "call_graph": {}
    },
    "src\\translation\\engines\\__init__.py": {
      "language": "python",
      "parsed": false
    },
    "src\\translation\\utils\\language_detector.py": {
      "language": "python",
      "parsed": true,
      "imports": [
        "logging",
        "typing",
        "langdetect"
      ],
      "functions": {},
      "classes": {
        "LanguageDetector": {
          "methods": {
            "__init__": {
              "doc": "Initialize the language detector.",
              "calls": [
                "_initialize_detector"
              ],
              "signature": "(self)",
              "called_by": [
                "TranscriptionWorker.__init__",
                "MainWindow.__init__"
              ]
            },
            "_initialize_detector": {
              "doc": "Initialize the detection backend.",
              "signature": "(self)",
              "called_by": [
                "LanguageDetector.__init__"
              ]
            },
            "detect": {
              "calls": [
                "_heuristic_detection"
              ],
              "signature": "(self, text: str) -> Optional[str]"
            },
            "detect_with_confidence": {
              "calls": [
                "_heuristic_detection"
              ],
              "signature": "(self, text: str) -> List[Dict[str, float]]"
            },
            "_heuristic_detection": {
              "signature": "(self, text: str) -> Optional[str]",
              "called_by": [
                "LanguageDetector.detect",
                "LanguageDetector.detect_with_confidence"
              ]
            },
            "is_supported": "(self, lang_code: str) -> bool",
            "get_language_name": "(self, lang_code: str) -> str",
            "get_supported_languages": {
              "decorators": [
                "staticmethod"
              ],
              "doc": "Get dictionary of supported language codes and names.",
              "signature": "() -> Dict[str, str]",
              "called_by": [
                "SubtitleTranslator.get_supported_languages"
              ]
            }
          },
          "class_constants": {
            "LANGUAGE_CODES": "collection"
          },
          "properties": [
            "text",
            "text",
            "text",
            "lang_code",
            "lang_code"
          ]
        }
      },
      "call_graph": {}
    },
    "src\\translation\\utils\\__init__.py": {
      "language": "python",
      "parsed": false
    }
  },
  "dependency_graph": {
    "run.py": [
      "sys",
      "pathlib",
      "src.ui.main_window",
      "PyQt6.QtWidgets"
    ],
    "test_direct_translation.py": [
      "sys",
      "pathlib",
      "traceback",
      "src.translation.subtitle_translator"
    ],
    "test_portuguese_translation.py": [
      "sys",
      "os",
      "pathlib",
      "src.translation.subtitle_translator",
      "src.translation.engines.tower_translator",
      "torch",
      "src.translation.utils.language_detector",
      "traceback"
    ],
    "test_translation.py": [
      "sys",
      "pathlib",
      "src.translation.subtitle_translator",
      "src.translation.engines.helsinki_translator"
    ],
    "test_ui_crash.py": [
      "sys",
      "pathlib",
      "PyQt6.QtWidgets",
      "src.ui.styles.modern_theme",
      "traceback",
      "src.translation.engines.tower_translator",
      "traceback"
    ],
    "tests\\test_audio_processing\\test_converter.py": [
      "pytest",
      "src.audio_processing.converter",
      "pathlib",
      "os"
    ],
    "tests\\test_audio_processing\\test_splitter.py": [
      "unittest",
      "pathlib",
      "shutil",
      "sys",
      "src.audio_processing.splitter"
    ],
    "tests\\test_input_handling\\test_file_handler.py": [
      "pytest",
      "src.input_handling.file_handler",
      "os"
    ],
    "tests\\test_repetition_fix\\test_audio_segmentation.py": [
      "pytest",
      "pathlib",
      "tempfile",
      "shutil",
      "unittest.mock",
      "pydub",
      "numpy",
      "src.audio_processing.splitter"
    ],
    "tests\\test_repetition_fix\\test_integration.py": [
      "pytest",
      "unittest.mock",
      "pathlib",
      "tempfile",
      "shutil",
      "src.transcription.transcription_pipeline",
      "src.post_processing.text_processor",
      "src.post_processing.text_processor",
      "src.post_processing.text_processor",
      "src.post_processing.text_processor"
    ],
    "tests\\test_repetition_fix\\test_text_combiner.py": [
      "pytest",
      "unittest.mock",
      "pathlib",
      "tempfile",
      "src.post_processing.combiner",
      "src.post_processing.combiner"
    ],
    "tests\\test_repetition_fix\\test_text_deduplication.py": [
      "pytest",
      "unittest.mock",
      "pathlib",
      "src.post_processing.text_processor",
      "time"
    ],
    "tests\\test_repetition_fix\\test_whisper_configuration.py": [
      "pytest",
      "unittest.mock",
      "pathlib",
      "tempfile",
      "src.transcription.whisper_manager",
      "shutil"
    ],
    "tests\\test_transcription\\test_pipeline.py": [
      "sys",
      "pathlib",
      "src.transcription.transcription_pipeline",
      "time"
    ],
    "tests\\test_transcription\\test_queue.py": [
      "sys",
      "pathlib",
      "src.transcription.transcription_pipeline",
      "time"
    ],
    "tests\\test_transcription\\test_whisper_manager.py": [
      "sys",
      "pathlib",
      "src.transcription.whisper_manager",
      "time"
    ],
    "src\\audio_processing\\converter.py": [
      "pathlib",
      "ffmpeg",
      "typing",
      "logging",
      "time",
      "os",
      "subprocess",
      "datetime"
    ],
    "src\\audio_processing\\splitter.py": [
      "pathlib",
      "typing",
      "math",
      "pydub",
      "logging"
    ],
    "src\\audio_processing\\vad_manager.py": [
      "torch",
      "torchaudio",
      "pathlib",
      "typing",
      "logging",
      "numpy",
      "pydub",
      "pydub.utils",
      "tempfile",
      "os",
      "warnings"
    ],
    "src\\config\\settings.py": [
      "json",
      "os",
      "pathlib",
      "typing",
      "logging"
    ],
    "src\\input_handling\\file_handler.py": [
      "pathlib",
      "typing"
    ],
    "src\\input_handling\\queue_manager.py": [
      "pathlib",
      "typing",
      "dataclasses",
      "enum",
      "threading",
      "logging"
    ],
    "src\\post_processing\\advanced_text_processor.py": [
      "re",
      "typing",
      "logging"
    ],
    "src\\post_processing\\combiner.py": [
      "re",
      "difflib",
      "typing",
      "logging"
    ],
    "src\\post_processing\\text_processor.py": [
      "re",
      "typing",
      "logging"
    ],
    "src\\subtitles\\smart_timing_estimator.py": [
      "typing",
      "logging",
      "re"
    ],
    "src\\subtitles\\subtitle_generator.py": [
      "pysubs2",
      "pathlib",
      "typing",
      "logging",
      "re",
      "math",
      "src.subtitles.word_level_analyzer",
      "src.subtitles.subtitle_timing_fixer",
      "src.subtitles.smart_timing_estimator",
      "src.subtitles.word_based_subtitle_generator",
      "src.audio_processing.vad_manager"
    ],
    "src\\subtitles\\subtitle_timing_fixer.py": [
      "typing",
      "logging"
    ],
    "src\\subtitles\\word_based_subtitle_generator.py": [
      "pathlib",
      "typing",
      "pysubs2",
      "logging"
    ],
    "src\\subtitles\\word_level_analyzer.py": [
      "typing",
      "logging",
      "math"
    ],
    "src\\transcription\\enhanced_whisper_manager.py": [
      "os",
      "pathlib",
      "typing",
      "faster_whisper",
      "torch",
      "time",
      "logging",
      "datetime",
      "tempfile",
      "pydub",
      "src.audio_processing.vad_manager"
    ],
    "src\\transcription\\transcription_pipeline.py": [
      "pathlib",
      "typing",
      "logging",
      "time",
      "datetime",
      "src.audio_processing.converter",
      "src.transcription.whisper_manager",
      "src.transcription.enhanced_whisper_manager",
      "src.post_processing.text_processor",
      "src.post_processing.advanced_text_processor",
      "src.post_processing.combiner",
      "src.subtitles.subtitle_generator"
    ],
    "src\\transcription\\whisper_manager.py": [
      "pathlib",
      "typing",
      "whisper",
      "torch",
      "time",
      "logging",
      "datetime",
      "os"
    ],
    "src\\translation\\subtitle_translator.py": [
      "logging",
      "pathlib",
      "typing",
      "pysubs2",
      "json",
      "re",
      "langdetect"
    ],
    "src\\ui\\main_window.py": [
      "PyQt6.QtWidgets",
      "PyQt6.QtCore",
      "PyQt6.QtGui",
      "pathlib",
      "src.transcription.transcription_pipeline",
      "src.input_handling.queue_manager",
      "src.ui.worker",
      "src.ui.styles.modern_theme",
      "src.config.settings",
      "logging",
      "time",
      "datetime",
      "src.translation.engines.tower_translator"
    ],
    "src\\ui\\main_window_old.py": [
      "PyQt6.QtCore",
      "PyQt6.QtGui",
      "pathlib",
      "src.transcription.transcription_pipeline",
      "src.input_handling.queue_manager",
      "src.ui.worker",
      "src.ui.styles.modern_theme",
      "logging",
      "time",
      "datetime"
    ],
    "src\\ui\\worker.py": [
      "PyQt6.QtCore",
      "pathlib",
      "time",
      "logging",
      "datetime",
      "src.translation.subtitle_translator",
      "sys",
      "traceback",
      "src.translation.subtitle_translator",
      "traceback",
      "traceback",
      "traceback"
    ],
    "src\\translation\\engines\\helsinki_translator.py": [
      "logging",
      "re",
      "typing",
      "pathlib",
      "transformers",
      "torch",
      "torch"
    ],
    "src\\translation\\engines\\tower_translator.py": [
      "logging",
      "re",
      "typing",
      "torch",
      "transformers"
    ],
    "src\\translation\\utils\\language_detector.py": [
      "logging",
      "typing",
      "langdetect"
    ]
  },
  "staleness_check": 1760540396.658818
}